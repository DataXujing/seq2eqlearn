{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to seq2seq learning\n\n\nMore learning: XuJing'Home \nhttps://dataxujing.coding.me/\n\n\n\n\n\n\n\n\nseq2seq\u7b80\u4ecb\n\n\n\n\n\n\nEncoder-Decoder\u7ed3\u6784\n\n\n\n\n\n\nseq2seq\u6a21\u578b\u539f\u7406\n\n\n\n\n\n\n\u5b9e\u73b0\u6587\u672cQA\u8f6f\u4ef6\n\n\n\n\n\n\n\u5b9e\u73b0(\u8054\u4fe1)QA\u7cfb\u7edf\u7684\u53ef\u884c\u6027\n\n\n\n\n\n\n\n\n\u672c\u6559\u7a0b\u901a\u8fc7\u8be6\u7ec6\u4ecb\u7ecdseq2seq\u6a21\u578b\u7406\u8bba\uff0c\u5e76\u8fdb\u4e00\u6b65\u5b9e\u73b0\u4e86\u57fa\u4e8eseq2seq\u7684\u6587\u672cQA\u7cfb\u7edf\u5c0f\u8f6f\u4ef6\u3002 \u7ed3\u5408\u7b2c\u4e09\u65b9\u7684\u8bed\u97f3\u8bc6\u522b\u53ca\u8f6c\u6362\u7cfb\u7edf\uff0c\u6700\u7ec8\u5b9e\u73b0\u8bed\u97f3QA\u7cfb\u7edf\u8f6f\u4ef6\u3002\n\n\n\u6700\u7ec8\u4f1a\u5f88\u5bb9\u6613\u7684\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8e\u50ac\u6536\u7684QA\u7cfb\u7edf\uff0c\u4f46\u662f\u6211\u4eec\u771f\u7684\u4f1a\u7528\u673a\u5668\u4eba\u53bb\u505a\u50ac\u6536\u5417\uff1f\n\n\n\u4e2a\u4eba\u89c2\u70b9\uff1a \u901a\u8fc7\u6e20\u9053\u4e86\u89e3\u76ee\u524d\u5e02\u9762\u4e0a\u7684\u673a\u5668\u4eba\u7684\u667a\u5546\u76f8\u5f53\u4e8e\u4e03\u516b\u5c81\u7684\u5b69\u7ae5\uff0c\u7528\u804a\u5929\u673a\u5668\u4eba\u66ff\u4ee3\u6216\u534a\u66ff\u4ee3\u4e00\u4e2a\u8bad\u7ec3\u6709\u7d20\u7684\u6cd5\u52a1\u5b8c\u6210\u590d\u6742\u7684\u50ac\u6536\u6d41\u7a0b\u57fa\u672c\u4e0d\u53ef\u80fd\u3002 \u6211\u4eec\u6709\u5927\u91cf\u7684\u52a3\u8d28\u6848\u4ef6\u8ba9\u50ac\u6536QA\u7cfb\u7edf\u53bb\u5c1d\u8bd5\uff0c\u4f7f\u5176\u5904\u7406\u4e00\u4e9b\u9ad8\u6210\u672c\u7684\u6848\u4ef6\u662f\u5b8c\u5168\u6709\u5fc5\u8981\u7684\u3002",
            "title": "\u4e3b\u9875"
        },
        {
            "location": "/#welcome-to-seq2seq-learning",
            "text": "More learning: XuJing'Home  https://dataxujing.coding.me/     seq2seq\u7b80\u4ecb    Encoder-Decoder\u7ed3\u6784    seq2seq\u6a21\u578b\u539f\u7406    \u5b9e\u73b0\u6587\u672cQA\u8f6f\u4ef6    \u5b9e\u73b0(\u8054\u4fe1)QA\u7cfb\u7edf\u7684\u53ef\u884c\u6027     \u672c\u6559\u7a0b\u901a\u8fc7\u8be6\u7ec6\u4ecb\u7ecdseq2seq\u6a21\u578b\u7406\u8bba\uff0c\u5e76\u8fdb\u4e00\u6b65\u5b9e\u73b0\u4e86\u57fa\u4e8eseq2seq\u7684\u6587\u672cQA\u7cfb\u7edf\u5c0f\u8f6f\u4ef6\u3002 \u7ed3\u5408\u7b2c\u4e09\u65b9\u7684\u8bed\u97f3\u8bc6\u522b\u53ca\u8f6c\u6362\u7cfb\u7edf\uff0c\u6700\u7ec8\u5b9e\u73b0\u8bed\u97f3QA\u7cfb\u7edf\u8f6f\u4ef6\u3002  \u6700\u7ec8\u4f1a\u5f88\u5bb9\u6613\u7684\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8e\u50ac\u6536\u7684QA\u7cfb\u7edf\uff0c\u4f46\u662f\u6211\u4eec\u771f\u7684\u4f1a\u7528\u673a\u5668\u4eba\u53bb\u505a\u50ac\u6536\u5417\uff1f  \u4e2a\u4eba\u89c2\u70b9\uff1a \u901a\u8fc7\u6e20\u9053\u4e86\u89e3\u76ee\u524d\u5e02\u9762\u4e0a\u7684\u673a\u5668\u4eba\u7684\u667a\u5546\u76f8\u5f53\u4e8e\u4e03\u516b\u5c81\u7684\u5b69\u7ae5\uff0c\u7528\u804a\u5929\u673a\u5668\u4eba\u66ff\u4ee3\u6216\u534a\u66ff\u4ee3\u4e00\u4e2a\u8bad\u7ec3\u6709\u7d20\u7684\u6cd5\u52a1\u5b8c\u6210\u590d\u6742\u7684\u50ac\u6536\u6d41\u7a0b\u57fa\u672c\u4e0d\u53ef\u80fd\u3002 \u6211\u4eec\u6709\u5927\u91cf\u7684\u52a3\u8d28\u6848\u4ef6\u8ba9\u50ac\u6536QA\u7cfb\u7edf\u53bb\u5c1d\u8bd5\uff0c\u4f7f\u5176\u5904\u7406\u4e00\u4e9b\u9ad8\u6210\u672c\u7684\u6848\u4ef6\u662f\u5b8c\u5168\u6709\u5fc5\u8981\u7684\u3002",
            "title": "Welcome to seq2seq learning"
        },
        {
            "location": "/chapter1/",
            "text": "seq2seq\u4ecb\u7ecd\n\n\n1.\u7b80\u5355\u4ecb\u7ecd\n\n\nSeq2Seq\u6280\u672f\uff0c\u5168\u79f0Sequence to Sequence\uff0c\u8be5\u6280\u672f\u7a81\u7834\u4e86\u4f20\u7edf\u7684\u56fa\u5b9a\u5927\u5c0f\u8f93\u5165\u95ee\u9898\u6846\u67b6\uff0c\u5f00\u901a\u4e86\u5c06\u7ecf\u5178\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08DNNs\uff09\u8fd0\u7528\u4e8e\u5728\u7ffb\u8bd1\uff0c\u6587\u672c\u81ea\u52a8\u6458\u8981\u548c\u673a\u5668\u4eba\u81ea\u52a8\u95ee\u7b54\u4ee5\u53ca\u4e00\u4e9b\u56de\u5f52\u9884\u6d4b\u4efb\u52a1\u4e0a,\u5e76\u88ab\u8bc1\u5b9e\u5728\u82f1\u8bed\uff0d\u6cd5\u8bed\u7ffb\u8bd1\u3001\u82f1\u8bed\uff0d\u5fb7\u8bed\u7ffb\u8bd1\u4ee5\u53ca\u4eba\u673a\u77ed\u95ee\u5feb\u7b54\u7684\u5e94\u7528\u4e2d\u6709\u7740\u4e0d\u4fd7\u7684\u8868\u73b0\u3002\n\n\n2.\u6a21\u578b\u7684\u63d0\u51fa\n\n\n\u63d0\u51fa\uff1aSeq2Seq\u88ab\u63d0\u51fa\u4e8e2014\u5e74\uff0c\u6700\u65e9\u7531\u4e24\u7bc7\u6587\u7ae0\u72ec\u7acb\u5730\u9610\u8ff0\u4e86\u5b83\u4e3b\u8981\u601d\u60f3\uff0c\u5206\u522b\u662fGoogle Brain\u56e2\u961f\u7684\u300aSequence to Sequence Learning with Neural Networks\u300b\u548cYoshua Bengio\u56e2\u961f\u7684\u300aLearning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation\u300b\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u9488\u5bf9\u673a\u5668\u7ffb\u8bd1\u7684\u95ee\u9898\u4e0d\u8c0b\u800c\u5408\u5730\u63d0\u51fa\u4e86\u76f8\u4f3c\u7684\u89e3\u51b3\u601d\u8def\uff0cSeq2Seq\u7531\u6b64\u4ea7\u751f\u3002\n\n\n3.\u6838\u5fc3\u601d\u60f3\n\n\nSeq2Seq\u89e3\u51b3\u95ee\u9898\u7684\u4e3b\u8981\u601d\u8def\u662f\u901a\u8fc7\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08\u5e38\u7528\u7684\u662fLSTM\uff0c\u957f\u77ed\u8bb0\u5fc6\u7f51\u7edc\uff0c\u4e00\u79cd\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff09\nhttp://dataxujing.coding.me/\u6df1\u5ea6\u5b66\u4e60\u4e4bRNN/\n\u3002\u5c06\u4e00\u4e2a\u4f5c\u4e3a\u8f93\u5165\u7684\u5e8f\u5217\u6620\u5c04\u4e3a\u4e00\u4e2a\u4f5c\u4e3a\u8f93\u51fa\u7684\u5e8f\u5217\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u7531\u7f16\u7801\uff08Encoder\uff09\u8f93\u5165\u4e0e\u89e3\u7801\uff08Decoder\uff09\u8f93\u51fa\u4e24\u4e2a\u73af\u8282\u7ec4\u6210, \u524d\u8005\u8d1f\u8d23\u628a\u5e8f\u5217\u7f16\u7801\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf\uff0c\u8fd9\u4e2a\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\u4f20\u7ed9\u540e\u8005\uff0c\u8f93\u51fa\u53ef\u53d8\u957f\u5ea6\u7684\u5411\u91cf\u3002\n\n\n\n\n\n\n\n\n\n\u56fe1\uff1aSeq2Seq\u793a\u610f\u56fe\n\n\n\u7531\u4e0a\u56fe\u6240\u793a\uff0c\u5728\u8fd9\u4e2a\u6a21\u578b\u4e2d\u6bcf\u4e00\u65f6\u95f4\u7684\u8f93\u5165\u548c\u8f93\u51fa\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u6bd4\u5982\u5bf9\u4e8e\u5e8f\u5217\u6570\u636e\u5c31\u662f\u5c06\u5e8f\u5217\u9879\u4f9d\u6b21\u4f20\u5165\uff0c\u6bcf\u4e2a\u5e8f\u5217\u9879\u518d\u5bf9\u5e94\u4e0d\u540c\u7684\u8f93\u51fa\u3002\u6bd4\u5982\u8bf4\u6211\u4eec\u73b0\u5728\u6709\u5e8f\u5217\u201cA B C EOS\u201d \uff08\u5176\u4e2dEOS\uff1dEnd of Sentence\uff0c\u53e5\u672b\u6807\u8bc6\u7b26\uff09\u4f5c\u4e3a\u8f93\u5165\uff0c\u90a3\u4e48\u6211\u4eec\u7684\u76ee\u7684\u5c31\u662f\u5c06\u201cA\u201d\uff0c\u201cB\u201d\uff0c\u201cC\u201d\uff0c\u201cEOS\u201d\u4f9d\u6b21\u4f20\u5165\u6a21\u578b\u540e\uff0c\u628a\u5176\u6620\u5c04\u4e3a\u5e8f\u5217\u201cW X Y Z EOS\u201d\u4f5c\u4e3a\u8f93\u51fa\u3002\n\n\n4.\u6a21\u578b\u5e94\u7528\n\n\nseq2seq\u5176\u5b9e\u53ef\u4ee5\u7528\u5728\u5f88\u591a\u5730\u65b9\uff0c\u6bd4\u5982\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u5bf9\u8bdd\u673a\u5668\u4eba\uff0c\u6587\u6863\u6458\u8981\u81ea\u52a8\u751f\u6210\uff0c\u56fe\u7247\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u3002\u6bd4\u5982Google\u5c31\u57fa\u4e8eseq2seq\u5f00\u53d1\u4e86\u4e00\u4e2a\u5bf9\u8bdd\u6a21\u578b[5]\uff0c\u548c\u8bba\u6587[1\uff0c2]\u7684\u601d\u8def\u57fa\u672c\u662f\u4e00\u81f4\u7684\uff0c\u4f7f\u7528\u4e24\u4e2aLSTM\u7684\u7ed3\u6784\uff0cLSTM1\u5c06\u8f93\u5165\u7684\u5bf9\u8bdd\u7f16\u7801\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5b9e\u6570\u5411\u91cf\uff0cLSTM2\u6839\u636e\u8fd9\u4e2a\u5411\u91cf\u4e0d\u505c\u5730\u9884\u6d4b\u540e\u9762\u7684\u8f93\u51fa\uff08\u89e3\u7801\uff09\u3002\u53ea\u662f\u5728\u5bf9\u8bdd\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528\u7684\u8bed\u6599\u662f\uff08\uff08input\uff09\u4f60\u8bf4\u7684\u8bdd-\u6211\u7b54\u7684\u8bdd\uff08input\uff09\uff09\u8fd9\u79cd\u7c7b\u578b\u7684pairs \u3002\u800c\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u4f7f\u7528\u7684\u8bed\u6599\u662f\uff08hello-\u4f60\u597d\uff09\u8fd9\u6837\u7684pairs\u3002\n\n\n\u6b64\u5916\uff0c\u5982\u679c\u6211\u4eec\u7684\u8f93\u5165\u662f\u56fe\u7247\uff0c\u8f93\u51fa\u662f\u5bf9\u56fe\u7247\u7684\u63cf\u8ff0\uff0c\u7528\u8fd9\u6837\u7684\u65b9\u5f0f\u6765\u8bad\u7ec3\u7684\u8bdd\u5c31\u80fd\u591f\u5b8c\u6210\u56fe\u7247\u63cf\u8ff0\u7684\u4efb\u52a1\u3002\u7b49\u7b49\uff0c\u7b49\u7b49\u3002\n\n\n\u53ef\u4ee5\u770b\u51fa\u6765\uff0cseq2seq\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\uff0c\u800c\u4e14\u6548\u679c\u4e5f\u662f\u975e\u5e38\u5f3a\u5927\u3002\u540c\u65f6\uff0c\u56e0\u4e3a\u662f\u7aef\u5230\u7aef\u7684\u6a21\u578b\uff08\u5927\u90e8\u5206\u7684\u6df1\u5ea6\u6a21\u578b\u90fd\u662f\u7aef\u5230\u7aef\u7684\uff09\uff0c\u5b83\u51cf\u5c11\u4e86\u5f88\u591a\u4eba\u5de5\u5904\u7406\u548c\u89c4\u5219\u5236\u5b9a\u7684\u6b65\u9aa4\u3002\u5728 Encoder-Decoder \u7684\u57fa\u7840\u4e0a\uff0c\u4eba\u4eec\u53c8\u5f15\u5165\u4e86attention mechanism\u7b49\u6280\u672f\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6df1\u5ea6\u65b9\u6cd5\u5728\u5404\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u52a0\u7a81\u51fa\u3002\n\n\n5.Paper\n\n\n\u9996\u5148\u4ecb\u7ecd\u51e0\u7bc7\u6bd4\u8f83\u91cd\u8981\u7684 seq2seq \u76f8\u5173\u7684\u8bba\u6587\uff1a \n\n\n[1] \nCho et al., 2014 . Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.\n \n\n\n[2] \nSutskever et al., 2014. Sequence to Sequence Learning with Neural Networks.\n\n\n[3] \nBahdanau et al., 2014. Neural Machine Translation by Jointly Learning to Align and Translate.\n \n\n\n[4] \nJean et. al., 2014. On Using Very Large Target Vocabulary for Neural Machine Translation.\n\n\n[5] \nVinyals et. al., 2015. A Neural Conversational Model. Computer Science.",
            "title": "Seq2Seq2\u7b80\u4ecb"
        },
        {
            "location": "/chapter1/#seq2seq",
            "text": "1.\u7b80\u5355\u4ecb\u7ecd  Seq2Seq\u6280\u672f\uff0c\u5168\u79f0Sequence to Sequence\uff0c\u8be5\u6280\u672f\u7a81\u7834\u4e86\u4f20\u7edf\u7684\u56fa\u5b9a\u5927\u5c0f\u8f93\u5165\u95ee\u9898\u6846\u67b6\uff0c\u5f00\u901a\u4e86\u5c06\u7ecf\u5178\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08DNNs\uff09\u8fd0\u7528\u4e8e\u5728\u7ffb\u8bd1\uff0c\u6587\u672c\u81ea\u52a8\u6458\u8981\u548c\u673a\u5668\u4eba\u81ea\u52a8\u95ee\u7b54\u4ee5\u53ca\u4e00\u4e9b\u56de\u5f52\u9884\u6d4b\u4efb\u52a1\u4e0a,\u5e76\u88ab\u8bc1\u5b9e\u5728\u82f1\u8bed\uff0d\u6cd5\u8bed\u7ffb\u8bd1\u3001\u82f1\u8bed\uff0d\u5fb7\u8bed\u7ffb\u8bd1\u4ee5\u53ca\u4eba\u673a\u77ed\u95ee\u5feb\u7b54\u7684\u5e94\u7528\u4e2d\u6709\u7740\u4e0d\u4fd7\u7684\u8868\u73b0\u3002  2.\u6a21\u578b\u7684\u63d0\u51fa  \u63d0\u51fa\uff1aSeq2Seq\u88ab\u63d0\u51fa\u4e8e2014\u5e74\uff0c\u6700\u65e9\u7531\u4e24\u7bc7\u6587\u7ae0\u72ec\u7acb\u5730\u9610\u8ff0\u4e86\u5b83\u4e3b\u8981\u601d\u60f3\uff0c\u5206\u522b\u662fGoogle Brain\u56e2\u961f\u7684\u300aSequence to Sequence Learning with Neural Networks\u300b\u548cYoshua Bengio\u56e2\u961f\u7684\u300aLearning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation\u300b\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u9488\u5bf9\u673a\u5668\u7ffb\u8bd1\u7684\u95ee\u9898\u4e0d\u8c0b\u800c\u5408\u5730\u63d0\u51fa\u4e86\u76f8\u4f3c\u7684\u89e3\u51b3\u601d\u8def\uff0cSeq2Seq\u7531\u6b64\u4ea7\u751f\u3002  3.\u6838\u5fc3\u601d\u60f3  Seq2Seq\u89e3\u51b3\u95ee\u9898\u7684\u4e3b\u8981\u601d\u8def\u662f\u901a\u8fc7\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08\u5e38\u7528\u7684\u662fLSTM\uff0c\u957f\u77ed\u8bb0\u5fc6\u7f51\u7edc\uff0c\u4e00\u79cd\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff09 http://dataxujing.coding.me/\u6df1\u5ea6\u5b66\u4e60\u4e4bRNN/ \u3002\u5c06\u4e00\u4e2a\u4f5c\u4e3a\u8f93\u5165\u7684\u5e8f\u5217\u6620\u5c04\u4e3a\u4e00\u4e2a\u4f5c\u4e3a\u8f93\u51fa\u7684\u5e8f\u5217\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u7531\u7f16\u7801\uff08Encoder\uff09\u8f93\u5165\u4e0e\u89e3\u7801\uff08Decoder\uff09\u8f93\u51fa\u4e24\u4e2a\u73af\u8282\u7ec4\u6210, \u524d\u8005\u8d1f\u8d23\u628a\u5e8f\u5217\u7f16\u7801\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf\uff0c\u8fd9\u4e2a\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\u4f20\u7ed9\u540e\u8005\uff0c\u8f93\u51fa\u53ef\u53d8\u957f\u5ea6\u7684\u5411\u91cf\u3002     \u56fe1\uff1aSeq2Seq\u793a\u610f\u56fe  \u7531\u4e0a\u56fe\u6240\u793a\uff0c\u5728\u8fd9\u4e2a\u6a21\u578b\u4e2d\u6bcf\u4e00\u65f6\u95f4\u7684\u8f93\u5165\u548c\u8f93\u51fa\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u6bd4\u5982\u5bf9\u4e8e\u5e8f\u5217\u6570\u636e\u5c31\u662f\u5c06\u5e8f\u5217\u9879\u4f9d\u6b21\u4f20\u5165\uff0c\u6bcf\u4e2a\u5e8f\u5217\u9879\u518d\u5bf9\u5e94\u4e0d\u540c\u7684\u8f93\u51fa\u3002\u6bd4\u5982\u8bf4\u6211\u4eec\u73b0\u5728\u6709\u5e8f\u5217\u201cA B C EOS\u201d \uff08\u5176\u4e2dEOS\uff1dEnd of Sentence\uff0c\u53e5\u672b\u6807\u8bc6\u7b26\uff09\u4f5c\u4e3a\u8f93\u5165\uff0c\u90a3\u4e48\u6211\u4eec\u7684\u76ee\u7684\u5c31\u662f\u5c06\u201cA\u201d\uff0c\u201cB\u201d\uff0c\u201cC\u201d\uff0c\u201cEOS\u201d\u4f9d\u6b21\u4f20\u5165\u6a21\u578b\u540e\uff0c\u628a\u5176\u6620\u5c04\u4e3a\u5e8f\u5217\u201cW X Y Z EOS\u201d\u4f5c\u4e3a\u8f93\u51fa\u3002  4.\u6a21\u578b\u5e94\u7528  seq2seq\u5176\u5b9e\u53ef\u4ee5\u7528\u5728\u5f88\u591a\u5730\u65b9\uff0c\u6bd4\u5982\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u5bf9\u8bdd\u673a\u5668\u4eba\uff0c\u6587\u6863\u6458\u8981\u81ea\u52a8\u751f\u6210\uff0c\u56fe\u7247\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u3002\u6bd4\u5982Google\u5c31\u57fa\u4e8eseq2seq\u5f00\u53d1\u4e86\u4e00\u4e2a\u5bf9\u8bdd\u6a21\u578b[5]\uff0c\u548c\u8bba\u6587[1\uff0c2]\u7684\u601d\u8def\u57fa\u672c\u662f\u4e00\u81f4\u7684\uff0c\u4f7f\u7528\u4e24\u4e2aLSTM\u7684\u7ed3\u6784\uff0cLSTM1\u5c06\u8f93\u5165\u7684\u5bf9\u8bdd\u7f16\u7801\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5b9e\u6570\u5411\u91cf\uff0cLSTM2\u6839\u636e\u8fd9\u4e2a\u5411\u91cf\u4e0d\u505c\u5730\u9884\u6d4b\u540e\u9762\u7684\u8f93\u51fa\uff08\u89e3\u7801\uff09\u3002\u53ea\u662f\u5728\u5bf9\u8bdd\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528\u7684\u8bed\u6599\u662f\uff08\uff08input\uff09\u4f60\u8bf4\u7684\u8bdd-\u6211\u7b54\u7684\u8bdd\uff08input\uff09\uff09\u8fd9\u79cd\u7c7b\u578b\u7684pairs \u3002\u800c\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u4f7f\u7528\u7684\u8bed\u6599\u662f\uff08hello-\u4f60\u597d\uff09\u8fd9\u6837\u7684pairs\u3002  \u6b64\u5916\uff0c\u5982\u679c\u6211\u4eec\u7684\u8f93\u5165\u662f\u56fe\u7247\uff0c\u8f93\u51fa\u662f\u5bf9\u56fe\u7247\u7684\u63cf\u8ff0\uff0c\u7528\u8fd9\u6837\u7684\u65b9\u5f0f\u6765\u8bad\u7ec3\u7684\u8bdd\u5c31\u80fd\u591f\u5b8c\u6210\u56fe\u7247\u63cf\u8ff0\u7684\u4efb\u52a1\u3002\u7b49\u7b49\uff0c\u7b49\u7b49\u3002  \u53ef\u4ee5\u770b\u51fa\u6765\uff0cseq2seq\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\uff0c\u800c\u4e14\u6548\u679c\u4e5f\u662f\u975e\u5e38\u5f3a\u5927\u3002\u540c\u65f6\uff0c\u56e0\u4e3a\u662f\u7aef\u5230\u7aef\u7684\u6a21\u578b\uff08\u5927\u90e8\u5206\u7684\u6df1\u5ea6\u6a21\u578b\u90fd\u662f\u7aef\u5230\u7aef\u7684\uff09\uff0c\u5b83\u51cf\u5c11\u4e86\u5f88\u591a\u4eba\u5de5\u5904\u7406\u548c\u89c4\u5219\u5236\u5b9a\u7684\u6b65\u9aa4\u3002\u5728 Encoder-Decoder \u7684\u57fa\u7840\u4e0a\uff0c\u4eba\u4eec\u53c8\u5f15\u5165\u4e86attention mechanism\u7b49\u6280\u672f\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6df1\u5ea6\u65b9\u6cd5\u5728\u5404\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u52a0\u7a81\u51fa\u3002  5.Paper  \u9996\u5148\u4ecb\u7ecd\u51e0\u7bc7\u6bd4\u8f83\u91cd\u8981\u7684 seq2seq \u76f8\u5173\u7684\u8bba\u6587\uff1a   [1]  Cho et al., 2014 . Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.    [2]  Sutskever et al., 2014. Sequence to Sequence Learning with Neural Networks.  [3]  Bahdanau et al., 2014. Neural Machine Translation by Jointly Learning to Align and Translate.    [4]  Jean et. al., 2014. On Using Very Large Target Vocabulary for Neural Machine Translation.  [5]  Vinyals et. al., 2015. A Neural Conversational Model. Computer Science.",
            "title": "seq2seq\u4ecb\u7ecd"
        },
        {
            "location": "/chapter2/",
            "text": "Encoder-Decoder\u7ed3\u6784\n\n\n1.\u7ecf\u5178\u7684Encoder-Decoder\u7ed3\u6784\n\n\n\n\n\n\n\n\n\n\u56fe2\uff1aEncoder-Decoder\u793a\u610f\u56fe\n\n\n\n\n\n\nEncoder\u610f\u601d\u662f\u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u5316\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf\n\n\n\n\n\n\nDecoder\u610f\u601d\u662f\u5c06\u8f93\u5165\u7684\u56fa\u5b9a\u957f\u5ea6\u5411\u91cf\u89e3\u7801\u6210\u8f93\u51fa\u5e8f\u5217\n\n\n\n\n\n\n\u5176\u4e2d\u7f16\u7801\u89e3\u7801\u7684\u65b9\u5f0f\u53ef\u4ee5\u662fRNN,CNN\u7b49\n\n\n\n\n\n\n\u5728\u673a\u5668\u7ffb\u8bd1\uff1a\u8f93\u5165\uff08hello\uff09 -> \u8f93\u51fa \uff08\u4f60\u597d\uff09\u3002\u8f93\u5165\u662f1\u4e2a\u82f1\u6587\u5355\u8bcd\uff0c\u8f93\u51fa\u4e3a2\u4e2a\u6c49\u5b57\u3002 \n\u5728\u5bf9\u8bdd\u673a\u5668\u4e2d\uff1a\u6211\u4eec\u63d0\uff08\u8f93\u5165\uff09\u4e00\u4e2a\u95ee\u9898\uff0c\u673a\u5668\u4f1a\u81ea\u52a8\u751f\u6210\uff08\u8f93\u51fa\uff09\u56de\u7b54\u3002\u8fd9\u91cc\u7684\u8f93\u5165\u548c\u8f93\u51fa\u663e\u7136\u662f\u957f\u5ea6\u6ca1\u6709\u786e\u5b9a\u7684\u5e8f\u5217\uff08sequences\uff09\u3002\n\n\n\n\n\n\n\u8981\u77e5\u9053\uff0c\u5728\u4ee5\u5f80\u7684\u5f88\u591a\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u4e00\u822c\u90fd\u8bf4\u8f93\u5165\u7279\u5f81\u77e9\u9635\uff0c\u6bcf\u4e2a\u6837\u672c\u5bf9\u5e94\u77e9\u9635\u4e2d\u7684\u67d0\u4e00\u884c\u3002\u5c31\u662f\u8bf4\uff0c\u65e0\u8bba\u662f\u7b2c\u4e00\u4e2a\u6837\u672c\u8fd8\u662f\u6700\u540e\u4e00\u4e2a\u6837\u672c\uff0c\u4ed6\u4eec\u90fd\u6709\u4e00\u6837\u7684\u7279\u5f81\u7ef4\u5ea6\u3002\u4f46\u662f\u5bf9\u4e8e\u7ffb\u8bd1\u8fd9\u79cd\u4f8b\u5b50\uff0c\u96be\u9053\u6211\u4eec\u8981\u8ba9\u6bcf\u4e00\u53e5\u8bdd\u90fd\u6709\u4e00\u6837\u7684\u5b57\u6570\u5417\uff0c\u90a3\u6837\u7684\u8bdd\u4f30\u8ba1\u4e94\u8a00\u5f8b\u8bd7\u548c\u4e03\u8a00\u7edd\u53e5\u53c8\u80fd\u5927\u706b\u4e00\u628a\u4e86\uff0c\u54c8\u54c8\u3002\u4f46\u662f\u8fd9\u4e0d\u79d1\u5b66\u5440\uff0c\u6240\u4ee5\u5c31\u6709\u4e86 seq2seq \u8fd9\u79cd\u7ed3\u6784\u3002\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u56fe3\uff1a\u7ecf\u5178\u7684Encoder-Decoder\u793a\u610f\u56fe\n\n\n\u4e0a\u56fe\u4e2d\uff0cC\u662fencoder\u8f93\u51fa\u7684\u6700\u7ec8\u72b6\u6001\uff0c\u5411\u91cfC\u901a\u5e38\u4e3aRNN\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u9690\u8282\u70b9\uff08h\uff0cHidden state\uff09\uff0c\u6216\u662f\u591a\u4e2a\u9690\u8282\u70b9\u7684\u52a0\u6743\u603b\u548c\uff0c\u4f5c\u4e3adecoder\u7684\u521d\u59cb\u72b6\u6001\uff1bW\u662fencoder\u7684\u6700\u7ec8\u8f93\u51fa\uff0c\u4f5c\u4e3adecoder\u7684\u521d\u59cb\u8f93\u5165\u3002\n\n\n\n\n\n\n\n\n\n\u56fe4\uff1a\u7ecf\u5178\u7684Encoder-Decoder\u793a\u610f\u56fe(LSTM or CNN\uff09\n\n\n\u4e0a\u56fe\u4e3aseq2seq\u7684encode\u548cdecode\u7ed3\u6784\uff0c\u91c7\u7528CNN/LSTM\u6a21\u578b\u3002\u5728RNN\u4e2d\uff0c\u5f53\u524d\u65f6\u95f4\u7684\u9690\u85cf\u72b6\u6001\u662f\u7531\u4e0a\u4e00\u65f6\u95f4\u7684\u72b6\u6001\u548c\u5f53\u524d\u65f6\u95f4\u7684\u8f93\u5165x\u5171\u540c\u51b3\u5b9a\u7684\uff0c\u5373\n\n\n\n\n\n\n\n\n\n\n\n\u3010\u7f16\u7801\u9636\u6bb5\u3011\n\n\n\n\n\u5f97\u5230\u5404\u4e2a\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u7136\u540e\u6c47\u603b\uff0c\u751f\u6210\u8bed\u4e49\u5411\u91cf\n\n\n\n\n\n\n\n\n\n\u4e5f\u53ef\u4ee5\u5c06\u6700\u540e\u7684\u4e00\u5c42\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u4f5c\u4e3a\u8bed\u4e49\u5411\u91cfC\n\n\n\n\n\n\n\n\n\n\n\n\u3010\u89e3\u7801\u9636\u6bb5\u3011\n\n\n\n\n\u8fd9\u4e2a\u9636\u6bb5\uff0c\u6211\u4eec\u8981\u6839\u636e\u7ed9\u5b9a\u7684\u8bed\u4e49\u5411\u91cfC\u548c\u8f93\u51fa\u5e8f\u5217y1,y2,\u2026yt1\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u7684\u5355\u8bcdyt\uff0c\u5373\n\n\n\n\n\n\n\n\n\n\u4e5f\u53ef\u4ee5\u5199\u505a\n\n\n\n\n\n\n\n\n\n\u5176\u4e2dg()\u4ee3\u8868\u7684\u662f\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002\u5728RNN\u4e2d\u53ef\u5199\u6210yt=g(yt1,ht,C)\uff0c\u5176\u4e2dh\u4e3a\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u3002\n\n\n2.Paper\u4e2d\u7684\u7ed3\u6784\u89e3\u6790\n\n\n\n\n--->\nCho et al., 2014 . Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.\n \n\n\n\n\n\n\n\n\n\n\n\n\u56fe5\uff1a\u8bba\u6587[1] \u6a21\u578b\u6309\u65f6\u95f4\u5c55\u5f00\u7684\u7ed3\u6784\n\n\n\u7b97\u662f\u6bd4\u8f83\u65e9\u63d0\u51faEncoder-Decoder\u8fd9\u79cd\u7ed3\u6784\u7684\uff0c\u5176\u4e2d Encoder \u90e8\u5206\u5e94\u8be5\u662f\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u5c31\u662f\u4e00\u4e2aRNNCell\uff08RNN \uff0cGRU\uff0cLSTM \u7b49\uff09 \u7ed3\u6784\u3002\u6bcf\u4e2a timestep\uff0c \u6211\u4eec\u5411 Encoder \u4e2d\u8f93\u5165\u4e00\u4e2a\u5b57/\u8bcd\uff08\u4e00\u822c\u662f\u8868\u793a\u8fd9\u4e2a\u5b57/\u8bcd\u7684\u4e00\u4e2a\u5b9e\u6570\u5411\u91cf\uff09\uff0c\u76f4\u5230\u6211\u4eec\u8f93\u5165\u8fd9\u4e2a\u53e5\u5b50\u7684\u6700\u540e\u4e00\u4e2a\u5b57/\u8bcd XT \uff0c\u7136\u540e\u8f93\u51fa\u6574\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u5411\u91cf c\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c c=hXT , XT \u662f\u6700\u540e\u4e00\u4e2a\u8f93\u5165\uff09\u3002\u56e0\u4e3a RNN \u7684\u7279\u70b9\u5c31\u662f\u628a\u524d\u9762\u6bcf\u4e00\u6b65\u7684\u8f93\u5165\u4fe1\u606f\u90fd\u8003\u8651\u8fdb\u6765\u4e86\uff0c\u6240\u4ee5\u7406\u8bba\u4e0a\u8fd9\u4e2a c \u5c31\u80fd\u591f\u628a\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u90fd\u5305\u542b\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u628a c \u5f53\u6210\u8fd9\u4e2a\u53e5\u5b50\u7684\u4e00\u4e2a\u8bed\u4e49\u8868\u793a\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u53e5\u5411\u91cf\u3002\u5728 Decoder \u4e2d\uff0c\u6211\u4eec\u6839\u636e Encoder \u5f97\u5230\u7684\u53e5\u5411\u91cf c\uff0c \u4e00\u6b65\u4e00\u6b65\u5730\u628a\u8574\u542b\u5728\u5176\u4e2d\u7684\u4fe1\u606f\u5206\u6790\u51fa\u6765\u3002\n\n\n\u8bba\u6587[1]\u4e2d\u7684\u516c\u5f0f\u8868\u793a\u5982\u4e0b\uff1a\n\n\nht=f(ht-1,yt\u22121,c) \n\n\n\n\u540c\u6837\uff0c\u6839\u636e ht \u6211\u4eec\u5c31\u80fd\u591f\u6c42\u51fa yt \u7684\u6761\u4ef6\u6982\u7387\uff1a\n\n\n\nP(yt|yt\u22121,yt\u22122,...,y1,c)=g(ht,yt\u22121,c)\n\n\n\n\n\n\u8fd9\u91cc\u6709\u4e24\u4e2a\u51fd\u6570 f \u548c g , \u4e00\u822c\u6765\u8bf4\uff0c f \u51fd\u6570\u7ed3\u6784\u5e94\u8be5\u662f\u4e00\u4e2a RNNCell \u7ed3\u6784\u6216\u8005\u7c7b\u4f3c\u7684\u7ed3\u6784\uff08\u8bba\u6587[1]\u539f\u6587\u4e2d\u7528\u7684\u662f GRU\uff09\uff1b\n\n\ng \u51fd\u6570\u4e00\u822c\u662f softmax \uff08\u6216\u8005\u662f\u8bba\u6587 [4] \u4e2d\u63d0\u51fa\u7684 sampled_softmax \u51fd\u6570\uff09\u3002\n\n\n\u6211\u4eec\u53ef\u4ee5\u5148\u8fd9\u6837\u6765\u7406\u89e3\uff1a\u5728 Encoder \u4e2d\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u6db5\u76d6\u4e86\u6574\u4e2a\u53e5\u5b50\u4fe1\u606f\u7684\u5b9e\u6570\u5411\u91cf c \uff0c\u73b0\u5728\u6211\u4eec\u4e00\u6b65\u4e00\u6b65\u7684\u4ece c \u4e2d\u62bd\u53d6\u4fe1\u606f\u3002\n\n\n\u9996\u5148\u7ed9 Decoder \u8f93\u5165\u4e00\u4e2a\u542f\u52a8\u4fe1\u53f7 y0(\u5982\u7279\u6b8a\u7b26\u53f7\n), \u7136\u540eDecoder \u6839\u636e h0,y0\uff0cc \uff0c\u5c31\u80fd\u591f\u8ba1\u7b97\u51fa y1 \u7684\u6982\u7387\u5206\u5e03\u4e86\n\n\n\u540c\u7406\uff0c\u6839\u636e h1,y1\uff0cc \u53ef\u4ee5\u8ba1\u7b97y2 \u7684\u6982\u7387\u5206\u5e03\u2026\u4ee5\u6b64\u7c7b\u63a8\u76f4\u5230\u9884\u6d4b\u5230\u7ed3\u675f\u7684\u7279\u6b8a\u6807\u5fd7 \n\uff0c\u624d\u7ed3\u675f\u9884\u6d4b\u3002\n\n\n\n\n\u8bba\u6587[1]Cho et al. \u4e2d\u9664\u4e86\u63d0\u51fa Encoder-Decoder \u8fd9\u6837\u4e00\u4e2a\u4f1f\u5927\u7684\u7ed3\u6784\u4ee5\u5916\uff0c\u8fd8\u6709\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u8d21\u732e\u5c31\u662f\u9996\u6b21\u63d0\u51fa\u4e86 Gated Recurrent Unit \uff08GRU\uff09\u8fd9\u4e2a\u4f7f\u7528\u9891\u7387\u975e\u5e38\u9ad8\u7684RNN\u7ed3\u6784\u3002\n\n\n\u6ce8\u610f\u5230\u5728\u8bba\u6587[1]Cho et al. \u7684\u6a21\u578b\u7ed3\u6784\u4e2d\uff08\u5982 \u56fe1 \u6240\u793a\uff09\uff0c\u4e2d\u95f4\u8bed\u4e49 c \u4e0d\u4ec5\u4ec5\u53ea\u4f5c\u7528\u4e8e decoder \u7684\u7b2c 1 \u4e2a\u65f6\u523b \uff0c\u800c\u662f\u6bcf\u4e2a\u65f6\u523b\u90fd\u6709 c \u8f93\u5165\u3002\u6240\u4ee5\uff0c\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c Decoder \u9884\u6d4b\u7b2c t \u4e2a timestep \u7684\u8f93\u51fa\u65f6\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \n\n\n\np(yt)=f(ht,yt\u22121,c)\n\n\n\n\u800c\u5728\u4e0b\u9762\u7684\u8bba\u6587[2] \u4e2d\uff0cDecoder \u9884\u6d4b\u7b2c t \u4e2a timestep \u7684\u8f93\u51fa\u65f6\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \n\n\np(yt)=f(ht,yt\u22121)\n\n\n\n\n--->\nSutskever et al., 2014. Sequence to Sequence Learning with Neural Networks.\n\n\n\n\n\n\n\n\n\n\n\n\u56fe6:\u8bba\u6587[2] \u6a21\u578b\u7ed3\u6784\n\n\n\n\n\u5728\u8bba\u6587[2] \u4e2d\uff0cEncoder \u6700\u540e\u8f93\u51fa\u7684\u4e2d\u95f4\u8bed\u4e49\u53ea\u4f5c\u7528\u4e8e Decoder \u7684\u7b2c\u4e00\u4e2a\u65f6\u523b\uff0c\u8fd9\u6837\u5b50\u6a21\u578b\u7406\u89e3\u8d77\u6765\u5176\u5b9e\u8981\u6bd4\u8bba\u6587[1] \u66f4\u5bb9\u6613\u4e00\u4e9b\u3002 \n\n\nEncoder-Decoder \u5176\u5b9e\u662f\u6700\u7b80\u5355\u7684\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u8bba\u6587[2] seq2seq \u6a21\u578b\u7ed3\u6784\uff08\u539f\u6587\u4e3a 4 \u5c42 LSTM\uff0c\u8fd9\u91cc\u5c55\u793a\u7684\u662f 1 \u5c42 LSTM\uff09\n\n\n\u56fe\u4e2d\u7684 Encoder \u548c Decoder \u90fd\u53ea\u5c55\u793a\u4e86\u4e00\u5c42\u7684\u666e\u901a\u7684 LSTMCell\u3002\u4ece\u4e0a\u9762\u7684\u7ed3\u6784\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6574\u4e2a\u6a21\u578b\u7ed3\u6784\u8fd8\u662f\u975e\u5e38\u7b80\u5355\u7684\u3002 EncoderCell \u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001 [cXT,hXT] \u5c31\u662f\u4e0a\u9762\u8bf4\u7684\u4e2d\u95f4\u8bed\u4e49\u5411\u91cf c \uff0c\u5b83\u5c06\u4f5c\u4e3a DecoderCell \u7684\u521d\u59cb\u72b6\u6001\u3002\u7136\u540e\u5728 DecoderCell \u4e2d\uff0c\u6bcf\u4e2a\u65f6\u523b\u7684\u8f93\u51fa\u5c06\u4f1a\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u5165\u3002\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230 DecoderCell \u67d0\u4e2a\u65f6\u523b\u9884\u6d4b\u8f93\u51fa\u7279\u6b8a\u7b26\u53f7 \n \u7ed3\u675f\u3002\n\n\n\n\n\u8bba\u6587 [2]Sutskever et al. \u4e5f\u662f\u6211\u4eec\u5728\u770b seq2seq \u8d44\u6599\u662f\u6700\u7ecf\u5e38\u63d0\u5230\u7684\u4e00\u7bc7\u6587\u7ae0\uff0c \u5728\u539f\u8bba\u6587\u4e2d\uff0c\u4e0a\u9762\u7684Encoder \u548c Decoder \u90fd\u662f 4 \u5c42\u7684 LSTM\uff0c\u4f46\u662f\u539f\u7406\u5176\u5b9e\u548c 1 \u5c42 LSTM \u662f\u4e00\u6837\u7684\u3002\u539f\u6587\u6709\u4e2a\u5c0f\u6280\u5de7\u601d\u60f3\u5728\u4e0a\u9762\u7684\u90ae\u4ef6\u5bf9\u8bdd\u6a21\u578b\u7ed3\u6784\u6ca1\u5c55\u793a\u51fa\u6765\uff0c\u5c31\u662f\u539f\u6587\u662f\u5e94\u7528\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\uff0c\u4f5c\u8005\u5c06\u6e90\u53e5\u5b50\u987a\u5e8f\u98a0\u5012\u540e\u518d\u8f93\u5165 Encoder \u4e2d\uff0c\u6bd4\u5982\u6e90\u53e5\u5b50\u4e3a\u201cA B C\u201d\uff0c\u90a3\u4e48\u8f93\u5165 Encoder \u7684\u987a\u5e8f\u4e3a \u201cC B A\u201d\uff0c\u7ecf\u8fc7\u8fd9\u6837\u7684\u5904\u7406\u540e\uff0c\u53d6\u5f97\u4e86\u5f88\u5927\u7684\u63d0\u5347\uff0c\u800c\u4e14\u8fd9\u6837\u7684\u5904\u7406\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5f88\u597d\u5730\u5904\u7406\u957f\u53e5\u5b50\u3002\u6b64\u5916\uff0cGoogle \u90a3\u7bc7\u4ecb\u7ecd\u673a\u5668\u5bf9\u8bdd\u7684\u6587\u7ae0\uff08\u8bba\u6587[5] \uff09\u7528\u7684\u5c31\u662f\u8fd9\u4e2a seq2seq \u6a21\u578b\u3002\n\n\n\n\n\n\n--->\nBahdanau et al., 2014. Neural Machine Translation by Jointly Learning to Align and Translate.\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\u56fe7\uff1a\u8bba\u6587[3] \u6a21\u578b\u7ed3\u6784\n\n\n\n\n\n\n\u6ce8\u610f\u673a\u5236\uff08Attention Mechanism\uff09,\u4f5c\u4e3aSeq2Seq\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u6ce8\u610f\u673a\u5236\u6700\u65e9\u7531Bahdanau\u7b49\u4eba\u4e8e2014\u5e74\u63d0\u51fa\uff0c\u8be5\u673a\u5236\u5b58\u5728\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u89e3\u51b3RNN\u4e2d\u53ea\u652f\u6301\u56fa\u5b9a\u957f\u5ea6\u8f93\u5165\u7684\u74f6\u9888\u3002\u5728\u8be5\u673a\u5236\u73af\u5883\u4e0b\uff0cSeq2Seq\u4e2d\u7684\u7f16\u7801\u5668\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\uff08bidirectional RNN\uff09\u3002 \n\n\n\n\n\n\n\u5728Decoder\u8fdb\u884c\u9884\u6d4b\u7684\u65f6\u5019\uff0cEncoder \u4e2d\u6bcf\u4e2a\u65f6\u523b\u7684\u9690\u85cf\u72b6\u6001\u90fd\u88ab\u5229\u7528\u4e0a\u4e86,\u8fd9\u6837\u5b50\uff0cEncoder \u5c31\u80fd\u5229\u7528\u591a\u4e2a\u8bed\u4e49\u4fe1\u606f\uff08\u9690\u85cf\u72b6\u6001\uff09\u6765\u8868\u8fbe\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u4e86\u3002\n\n\n\n\n\n\nEncoder\u7528\u7684\u662f\u53cc\u5411GRU\uff0c\u8fd9\u4e2a\u7ed3\u6784\u5176\u5b9e\u975e\u5e38\u76f4\u89c2\uff0c\u5728\u8fd9\u79cd seq2seq \u4e2d\u6548\u679c\u4e5f\u8981\u6bd4\u5355\u5411\u7684 GRU \u8981\u597d\u3002\n\n\n\n\n\n\n---->\nJean et. al., 2014. On Using Very Large Target Vocabulary for Neural Machine Translation.\n\n\n\n\n\n\n\u8bba\u6587[4]\u4ecb\u7ecd\u4e86\u673a\u5668\u7ffb\u8bd1\u5728\u8bad\u7ec3\u65f6\u7ecf\u5e38\u7528\u5230\u7684\u4e00\u4e2a\u65b9\u6cd5\uff08\u5c0f\u6280\u5de7\uff09sample_softmax \uff0c\u4e3b\u8981\u89e3\u51b3\u8bcd\u8868\u6570\u91cf\u592a\u5927\u7684\u95ee\u9898\u3002\n\n\n\n\nsampling softmax\u89e3\u51b3\u4e86softmax\u5206\u6bcd\u90e8\u5206\u8ba1\u7b97\u91cf\u5927\u7684\u95ee\u9898\uff0c\u5728\u8bcd\u5411\u91cf\u4e2d\u7528\u7684\u8f83\u591a\u3002\n\n\n\n\n\u4e0d\u662f\u672c\u8282\u91cd\u70b9\u8be6\u89c1[6]\u3002\n\n\n\n\n\n\n--->\nVinyals et. al., 2015. A Neural Conversational Model. Computer Science.\n\n\n\n\n\n\n\u4ecb\u7ecd\u4e86Google\u673a\u5668\u5bf9\u8bdd\uff0c\u7528\u7684\u6a21\u578b\u5c31\u662f[\u8bba\u65872]\u4e2d\u7684\u6a21\u578b\u3002\n\n\n3.\u53c2\u8003\u6587\u732e\n\n\n[1] \nhttps://www.jianshu.com/p/124b777e0c55\n\n\n[2] \nhttp://blog.csdn.net/Zsaang/article/details/71516253\n\n\n[3] \nhttp://blog.csdn.net/u012223913/article/details/77487610#t0\n\n\n[4] \nhttp://blog.csdn.net/jerr__y/article/details/53749693\n\n\n[5] \nhttp://blog.csdn.net/malefactor/article/details/50550211\n\n\n[6] \nhttp://blog.csdn.net/wangpeng138375/article/details/75151064",
            "title": "Encoder-Decoder\u7ed3\u6784"
        },
        {
            "location": "/chapter2/#encoder-decoder",
            "text": "1.\u7ecf\u5178\u7684Encoder-Decoder\u7ed3\u6784     \u56fe2\uff1aEncoder-Decoder\u793a\u610f\u56fe    Encoder\u610f\u601d\u662f\u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u5316\u6210\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u5411\u91cf    Decoder\u610f\u601d\u662f\u5c06\u8f93\u5165\u7684\u56fa\u5b9a\u957f\u5ea6\u5411\u91cf\u89e3\u7801\u6210\u8f93\u51fa\u5e8f\u5217    \u5176\u4e2d\u7f16\u7801\u89e3\u7801\u7684\u65b9\u5f0f\u53ef\u4ee5\u662fRNN,CNN\u7b49    \u5728\u673a\u5668\u7ffb\u8bd1\uff1a\u8f93\u5165\uff08hello\uff09 -> \u8f93\u51fa \uff08\u4f60\u597d\uff09\u3002\u8f93\u5165\u662f1\u4e2a\u82f1\u6587\u5355\u8bcd\uff0c\u8f93\u51fa\u4e3a2\u4e2a\u6c49\u5b57\u3002 \n\u5728\u5bf9\u8bdd\u673a\u5668\u4e2d\uff1a\u6211\u4eec\u63d0\uff08\u8f93\u5165\uff09\u4e00\u4e2a\u95ee\u9898\uff0c\u673a\u5668\u4f1a\u81ea\u52a8\u751f\u6210\uff08\u8f93\u51fa\uff09\u56de\u7b54\u3002\u8fd9\u91cc\u7684\u8f93\u5165\u548c\u8f93\u51fa\u663e\u7136\u662f\u957f\u5ea6\u6ca1\u6709\u786e\u5b9a\u7684\u5e8f\u5217\uff08sequences\uff09\u3002    \u8981\u77e5\u9053\uff0c\u5728\u4ee5\u5f80\u7684\u5f88\u591a\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u4e00\u822c\u90fd\u8bf4\u8f93\u5165\u7279\u5f81\u77e9\u9635\uff0c\u6bcf\u4e2a\u6837\u672c\u5bf9\u5e94\u77e9\u9635\u4e2d\u7684\u67d0\u4e00\u884c\u3002\u5c31\u662f\u8bf4\uff0c\u65e0\u8bba\u662f\u7b2c\u4e00\u4e2a\u6837\u672c\u8fd8\u662f\u6700\u540e\u4e00\u4e2a\u6837\u672c\uff0c\u4ed6\u4eec\u90fd\u6709\u4e00\u6837\u7684\u7279\u5f81\u7ef4\u5ea6\u3002\u4f46\u662f\u5bf9\u4e8e\u7ffb\u8bd1\u8fd9\u79cd\u4f8b\u5b50\uff0c\u96be\u9053\u6211\u4eec\u8981\u8ba9\u6bcf\u4e00\u53e5\u8bdd\u90fd\u6709\u4e00\u6837\u7684\u5b57\u6570\u5417\uff0c\u90a3\u6837\u7684\u8bdd\u4f30\u8ba1\u4e94\u8a00\u5f8b\u8bd7\u548c\u4e03\u8a00\u7edd\u53e5\u53c8\u80fd\u5927\u706b\u4e00\u628a\u4e86\uff0c\u54c8\u54c8\u3002\u4f46\u662f\u8fd9\u4e0d\u79d1\u5b66\u5440\uff0c\u6240\u4ee5\u5c31\u6709\u4e86 seq2seq \u8fd9\u79cd\u7ed3\u6784\u3002       \u56fe3\uff1a\u7ecf\u5178\u7684Encoder-Decoder\u793a\u610f\u56fe  \u4e0a\u56fe\u4e2d\uff0cC\u662fencoder\u8f93\u51fa\u7684\u6700\u7ec8\u72b6\u6001\uff0c\u5411\u91cfC\u901a\u5e38\u4e3aRNN\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u9690\u8282\u70b9\uff08h\uff0cHidden state\uff09\uff0c\u6216\u662f\u591a\u4e2a\u9690\u8282\u70b9\u7684\u52a0\u6743\u603b\u548c\uff0c\u4f5c\u4e3adecoder\u7684\u521d\u59cb\u72b6\u6001\uff1bW\u662fencoder\u7684\u6700\u7ec8\u8f93\u51fa\uff0c\u4f5c\u4e3adecoder\u7684\u521d\u59cb\u8f93\u5165\u3002     \u56fe4\uff1a\u7ecf\u5178\u7684Encoder-Decoder\u793a\u610f\u56fe(LSTM or CNN\uff09  \u4e0a\u56fe\u4e3aseq2seq\u7684encode\u548cdecode\u7ed3\u6784\uff0c\u91c7\u7528CNN/LSTM\u6a21\u578b\u3002\u5728RNN\u4e2d\uff0c\u5f53\u524d\u65f6\u95f4\u7684\u9690\u85cf\u72b6\u6001\u662f\u7531\u4e0a\u4e00\u65f6\u95f4\u7684\u72b6\u6001\u548c\u5f53\u524d\u65f6\u95f4\u7684\u8f93\u5165x\u5171\u540c\u51b3\u5b9a\u7684\uff0c\u5373      \u3010\u7f16\u7801\u9636\u6bb5\u3011   \u5f97\u5230\u5404\u4e2a\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u7136\u540e\u6c47\u603b\uff0c\u751f\u6210\u8bed\u4e49\u5411\u91cf     \u4e5f\u53ef\u4ee5\u5c06\u6700\u540e\u7684\u4e00\u5c42\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u4f5c\u4e3a\u8bed\u4e49\u5411\u91cfC      \u3010\u89e3\u7801\u9636\u6bb5\u3011   \u8fd9\u4e2a\u9636\u6bb5\uff0c\u6211\u4eec\u8981\u6839\u636e\u7ed9\u5b9a\u7684\u8bed\u4e49\u5411\u91cfC\u548c\u8f93\u51fa\u5e8f\u5217y1,y2,\u2026yt1\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u7684\u5355\u8bcdyt\uff0c\u5373     \u4e5f\u53ef\u4ee5\u5199\u505a     \u5176\u4e2dg()\u4ee3\u8868\u7684\u662f\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002\u5728RNN\u4e2d\u53ef\u5199\u6210yt=g(yt1,ht,C)\uff0c\u5176\u4e2dh\u4e3a\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u3002  2.Paper\u4e2d\u7684\u7ed3\u6784\u89e3\u6790   ---> Cho et al., 2014 . Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.        \u56fe5\uff1a\u8bba\u6587[1] \u6a21\u578b\u6309\u65f6\u95f4\u5c55\u5f00\u7684\u7ed3\u6784  \u7b97\u662f\u6bd4\u8f83\u65e9\u63d0\u51faEncoder-Decoder\u8fd9\u79cd\u7ed3\u6784\u7684\uff0c\u5176\u4e2d Encoder \u90e8\u5206\u5e94\u8be5\u662f\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u5c31\u662f\u4e00\u4e2aRNNCell\uff08RNN \uff0cGRU\uff0cLSTM \u7b49\uff09 \u7ed3\u6784\u3002\u6bcf\u4e2a timestep\uff0c \u6211\u4eec\u5411 Encoder \u4e2d\u8f93\u5165\u4e00\u4e2a\u5b57/\u8bcd\uff08\u4e00\u822c\u662f\u8868\u793a\u8fd9\u4e2a\u5b57/\u8bcd\u7684\u4e00\u4e2a\u5b9e\u6570\u5411\u91cf\uff09\uff0c\u76f4\u5230\u6211\u4eec\u8f93\u5165\u8fd9\u4e2a\u53e5\u5b50\u7684\u6700\u540e\u4e00\u4e2a\u5b57/\u8bcd XT \uff0c\u7136\u540e\u8f93\u51fa\u6574\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u5411\u91cf c\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c c=hXT , XT \u662f\u6700\u540e\u4e00\u4e2a\u8f93\u5165\uff09\u3002\u56e0\u4e3a RNN \u7684\u7279\u70b9\u5c31\u662f\u628a\u524d\u9762\u6bcf\u4e00\u6b65\u7684\u8f93\u5165\u4fe1\u606f\u90fd\u8003\u8651\u8fdb\u6765\u4e86\uff0c\u6240\u4ee5\u7406\u8bba\u4e0a\u8fd9\u4e2a c \u5c31\u80fd\u591f\u628a\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u90fd\u5305\u542b\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u628a c \u5f53\u6210\u8fd9\u4e2a\u53e5\u5b50\u7684\u4e00\u4e2a\u8bed\u4e49\u8868\u793a\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u53e5\u5411\u91cf\u3002\u5728 Decoder \u4e2d\uff0c\u6211\u4eec\u6839\u636e Encoder \u5f97\u5230\u7684\u53e5\u5411\u91cf c\uff0c \u4e00\u6b65\u4e00\u6b65\u5730\u628a\u8574\u542b\u5728\u5176\u4e2d\u7684\u4fe1\u606f\u5206\u6790\u51fa\u6765\u3002  \u8bba\u6587[1]\u4e2d\u7684\u516c\u5f0f\u8868\u793a\u5982\u4e0b\uff1a  ht=f(ht-1,yt\u22121,c)   \u540c\u6837\uff0c\u6839\u636e ht \u6211\u4eec\u5c31\u80fd\u591f\u6c42\u51fa yt \u7684\u6761\u4ef6\u6982\u7387\uff1a  \nP(yt|yt\u22121,yt\u22122,...,y1,c)=g(ht,yt\u22121,c)   \u8fd9\u91cc\u6709\u4e24\u4e2a\u51fd\u6570 f \u548c g , \u4e00\u822c\u6765\u8bf4\uff0c f \u51fd\u6570\u7ed3\u6784\u5e94\u8be5\u662f\u4e00\u4e2a RNNCell \u7ed3\u6784\u6216\u8005\u7c7b\u4f3c\u7684\u7ed3\u6784\uff08\u8bba\u6587[1]\u539f\u6587\u4e2d\u7528\u7684\u662f GRU\uff09\uff1b  g \u51fd\u6570\u4e00\u822c\u662f softmax \uff08\u6216\u8005\u662f\u8bba\u6587 [4] \u4e2d\u63d0\u51fa\u7684 sampled_softmax \u51fd\u6570\uff09\u3002  \u6211\u4eec\u53ef\u4ee5\u5148\u8fd9\u6837\u6765\u7406\u89e3\uff1a\u5728 Encoder \u4e2d\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u6db5\u76d6\u4e86\u6574\u4e2a\u53e5\u5b50\u4fe1\u606f\u7684\u5b9e\u6570\u5411\u91cf c \uff0c\u73b0\u5728\u6211\u4eec\u4e00\u6b65\u4e00\u6b65\u7684\u4ece c \u4e2d\u62bd\u53d6\u4fe1\u606f\u3002  \u9996\u5148\u7ed9 Decoder \u8f93\u5165\u4e00\u4e2a\u542f\u52a8\u4fe1\u53f7 y0(\u5982\u7279\u6b8a\u7b26\u53f7 ), \u7136\u540eDecoder \u6839\u636e h0,y0\uff0cc \uff0c\u5c31\u80fd\u591f\u8ba1\u7b97\u51fa y1 \u7684\u6982\u7387\u5206\u5e03\u4e86  \u540c\u7406\uff0c\u6839\u636e h1,y1\uff0cc \u53ef\u4ee5\u8ba1\u7b97y2 \u7684\u6982\u7387\u5206\u5e03\u2026\u4ee5\u6b64\u7c7b\u63a8\u76f4\u5230\u9884\u6d4b\u5230\u7ed3\u675f\u7684\u7279\u6b8a\u6807\u5fd7  \uff0c\u624d\u7ed3\u675f\u9884\u6d4b\u3002   \u8bba\u6587[1]Cho et al. \u4e2d\u9664\u4e86\u63d0\u51fa Encoder-Decoder \u8fd9\u6837\u4e00\u4e2a\u4f1f\u5927\u7684\u7ed3\u6784\u4ee5\u5916\uff0c\u8fd8\u6709\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u8d21\u732e\u5c31\u662f\u9996\u6b21\u63d0\u51fa\u4e86 Gated Recurrent Unit \uff08GRU\uff09\u8fd9\u4e2a\u4f7f\u7528\u9891\u7387\u975e\u5e38\u9ad8\u7684RNN\u7ed3\u6784\u3002  \u6ce8\u610f\u5230\u5728\u8bba\u6587[1]Cho et al. \u7684\u6a21\u578b\u7ed3\u6784\u4e2d\uff08\u5982 \u56fe1 \u6240\u793a\uff09\uff0c\u4e2d\u95f4\u8bed\u4e49 c \u4e0d\u4ec5\u4ec5\u53ea\u4f5c\u7528\u4e8e decoder \u7684\u7b2c 1 \u4e2a\u65f6\u523b \uff0c\u800c\u662f\u6bcf\u4e2a\u65f6\u523b\u90fd\u6709 c \u8f93\u5165\u3002\u6240\u4ee5\uff0c\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c Decoder \u9884\u6d4b\u7b2c t \u4e2a timestep \u7684\u8f93\u51fa\u65f6\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a   \np(yt)=f(ht,yt\u22121,c)  \u800c\u5728\u4e0b\u9762\u7684\u8bba\u6587[2] \u4e2d\uff0cDecoder \u9884\u6d4b\u7b2c t \u4e2a timestep \u7684\u8f93\u51fa\u65f6\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a  \np(yt)=f(ht,yt\u22121)   ---> Sutskever et al., 2014. Sequence to Sequence Learning with Neural Networks.      \u56fe6:\u8bba\u6587[2] \u6a21\u578b\u7ed3\u6784   \u5728\u8bba\u6587[2] \u4e2d\uff0cEncoder \u6700\u540e\u8f93\u51fa\u7684\u4e2d\u95f4\u8bed\u4e49\u53ea\u4f5c\u7528\u4e8e Decoder \u7684\u7b2c\u4e00\u4e2a\u65f6\u523b\uff0c\u8fd9\u6837\u5b50\u6a21\u578b\u7406\u89e3\u8d77\u6765\u5176\u5b9e\u8981\u6bd4\u8bba\u6587[1] \u66f4\u5bb9\u6613\u4e00\u4e9b\u3002   Encoder-Decoder \u5176\u5b9e\u662f\u6700\u7b80\u5355\u7684       \u8bba\u6587[2] seq2seq \u6a21\u578b\u7ed3\u6784\uff08\u539f\u6587\u4e3a 4 \u5c42 LSTM\uff0c\u8fd9\u91cc\u5c55\u793a\u7684\u662f 1 \u5c42 LSTM\uff09  \u56fe\u4e2d\u7684 Encoder \u548c Decoder \u90fd\u53ea\u5c55\u793a\u4e86\u4e00\u5c42\u7684\u666e\u901a\u7684 LSTMCell\u3002\u4ece\u4e0a\u9762\u7684\u7ed3\u6784\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6574\u4e2a\u6a21\u578b\u7ed3\u6784\u8fd8\u662f\u975e\u5e38\u7b80\u5355\u7684\u3002 EncoderCell \u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001 [cXT,hXT] \u5c31\u662f\u4e0a\u9762\u8bf4\u7684\u4e2d\u95f4\u8bed\u4e49\u5411\u91cf c \uff0c\u5b83\u5c06\u4f5c\u4e3a DecoderCell \u7684\u521d\u59cb\u72b6\u6001\u3002\u7136\u540e\u5728 DecoderCell \u4e2d\uff0c\u6bcf\u4e2a\u65f6\u523b\u7684\u8f93\u51fa\u5c06\u4f1a\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u5165\u3002\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230 DecoderCell \u67d0\u4e2a\u65f6\u523b\u9884\u6d4b\u8f93\u51fa\u7279\u6b8a\u7b26\u53f7   \u7ed3\u675f\u3002   \u8bba\u6587 [2]Sutskever et al. \u4e5f\u662f\u6211\u4eec\u5728\u770b seq2seq \u8d44\u6599\u662f\u6700\u7ecf\u5e38\u63d0\u5230\u7684\u4e00\u7bc7\u6587\u7ae0\uff0c \u5728\u539f\u8bba\u6587\u4e2d\uff0c\u4e0a\u9762\u7684Encoder \u548c Decoder \u90fd\u662f 4 \u5c42\u7684 LSTM\uff0c\u4f46\u662f\u539f\u7406\u5176\u5b9e\u548c 1 \u5c42 LSTM \u662f\u4e00\u6837\u7684\u3002\u539f\u6587\u6709\u4e2a\u5c0f\u6280\u5de7\u601d\u60f3\u5728\u4e0a\u9762\u7684\u90ae\u4ef6\u5bf9\u8bdd\u6a21\u578b\u7ed3\u6784\u6ca1\u5c55\u793a\u51fa\u6765\uff0c\u5c31\u662f\u539f\u6587\u662f\u5e94\u7528\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\uff0c\u4f5c\u8005\u5c06\u6e90\u53e5\u5b50\u987a\u5e8f\u98a0\u5012\u540e\u518d\u8f93\u5165 Encoder \u4e2d\uff0c\u6bd4\u5982\u6e90\u53e5\u5b50\u4e3a\u201cA B C\u201d\uff0c\u90a3\u4e48\u8f93\u5165 Encoder \u7684\u987a\u5e8f\u4e3a \u201cC B A\u201d\uff0c\u7ecf\u8fc7\u8fd9\u6837\u7684\u5904\u7406\u540e\uff0c\u53d6\u5f97\u4e86\u5f88\u5927\u7684\u63d0\u5347\uff0c\u800c\u4e14\u8fd9\u6837\u7684\u5904\u7406\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5f88\u597d\u5730\u5904\u7406\u957f\u53e5\u5b50\u3002\u6b64\u5916\uff0cGoogle \u90a3\u7bc7\u4ecb\u7ecd\u673a\u5668\u5bf9\u8bdd\u7684\u6587\u7ae0\uff08\u8bba\u6587[5] \uff09\u7528\u7684\u5c31\u662f\u8fd9\u4e2a seq2seq \u6a21\u578b\u3002    ---> Bahdanau et al., 2014. Neural Machine Translation by Jointly Learning to Align and Translate.         \u56fe7\uff1a\u8bba\u6587[3] \u6a21\u578b\u7ed3\u6784    \u6ce8\u610f\u673a\u5236\uff08Attention Mechanism\uff09,\u4f5c\u4e3aSeq2Seq\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u6ce8\u610f\u673a\u5236\u6700\u65e9\u7531Bahdanau\u7b49\u4eba\u4e8e2014\u5e74\u63d0\u51fa\uff0c\u8be5\u673a\u5236\u5b58\u5728\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u89e3\u51b3RNN\u4e2d\u53ea\u652f\u6301\u56fa\u5b9a\u957f\u5ea6\u8f93\u5165\u7684\u74f6\u9888\u3002\u5728\u8be5\u673a\u5236\u73af\u5883\u4e0b\uff0cSeq2Seq\u4e2d\u7684\u7f16\u7801\u5668\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\uff08bidirectional RNN\uff09\u3002     \u5728Decoder\u8fdb\u884c\u9884\u6d4b\u7684\u65f6\u5019\uff0cEncoder \u4e2d\u6bcf\u4e2a\u65f6\u523b\u7684\u9690\u85cf\u72b6\u6001\u90fd\u88ab\u5229\u7528\u4e0a\u4e86,\u8fd9\u6837\u5b50\uff0cEncoder \u5c31\u80fd\u5229\u7528\u591a\u4e2a\u8bed\u4e49\u4fe1\u606f\uff08\u9690\u85cf\u72b6\u6001\uff09\u6765\u8868\u8fbe\u6574\u4e2a\u53e5\u5b50\u7684\u4fe1\u606f\u4e86\u3002    Encoder\u7528\u7684\u662f\u53cc\u5411GRU\uff0c\u8fd9\u4e2a\u7ed3\u6784\u5176\u5b9e\u975e\u5e38\u76f4\u89c2\uff0c\u5728\u8fd9\u79cd seq2seq \u4e2d\u6548\u679c\u4e5f\u8981\u6bd4\u5355\u5411\u7684 GRU \u8981\u597d\u3002    ----> Jean et. al., 2014. On Using Very Large Target Vocabulary for Neural Machine Translation.    \u8bba\u6587[4]\u4ecb\u7ecd\u4e86\u673a\u5668\u7ffb\u8bd1\u5728\u8bad\u7ec3\u65f6\u7ecf\u5e38\u7528\u5230\u7684\u4e00\u4e2a\u65b9\u6cd5\uff08\u5c0f\u6280\u5de7\uff09sample_softmax \uff0c\u4e3b\u8981\u89e3\u51b3\u8bcd\u8868\u6570\u91cf\u592a\u5927\u7684\u95ee\u9898\u3002   sampling softmax\u89e3\u51b3\u4e86softmax\u5206\u6bcd\u90e8\u5206\u8ba1\u7b97\u91cf\u5927\u7684\u95ee\u9898\uff0c\u5728\u8bcd\u5411\u91cf\u4e2d\u7528\u7684\u8f83\u591a\u3002   \u4e0d\u662f\u672c\u8282\u91cd\u70b9\u8be6\u89c1[6]\u3002    ---> Vinyals et. al., 2015. A Neural Conversational Model. Computer Science.    \u4ecb\u7ecd\u4e86Google\u673a\u5668\u5bf9\u8bdd\uff0c\u7528\u7684\u6a21\u578b\u5c31\u662f[\u8bba\u65872]\u4e2d\u7684\u6a21\u578b\u3002  3.\u53c2\u8003\u6587\u732e  [1]  https://www.jianshu.com/p/124b777e0c55  [2]  http://blog.csdn.net/Zsaang/article/details/71516253  [3]  http://blog.csdn.net/u012223913/article/details/77487610#t0  [4]  http://blog.csdn.net/jerr__y/article/details/53749693  [5]  http://blog.csdn.net/malefactor/article/details/50550211  [6]  http://blog.csdn.net/wangpeng138375/article/details/75151064",
            "title": "Encoder-Decoder\u7ed3\u6784"
        },
        {
            "location": "/chapter3/",
            "text": "seq2seq\u6a21\u578bPython\u5b9e\u73b0\n\n\n\u672c\u8282\u4e3b\u8981\u8bb2\u89e3\u5982\u4f55\u7528tensorflow\u53cakeras\u5b9e\u73b0seq2seq2\u6a21\u578b\uff0c\u6211\u4eec\u540e\u671f\u7684\u8054\u4fe1\u6587\u672c\u804a\u5929\u673a\u5668\u4eba\u7684\u4e3b\u8981\u8bad\u7ec3\u6a21\u578b\u5c31\u91c7\u7528seq2seq\n\n\n\n\n1.tensorflow\u5b9e\u73b0seq2seq\n\n\nTensorflow 1.0.0 \u7248\u672c\u4ee5\u540e\uff0c\u5f00\u53d1\u4e86\u65b0\u7684seq2seq\u63a5\u53e3\uff0c\u5f03\u7528\u4e86\u539f\u6765\u7684\u63a5\u53e3\u3002\u65e7\u7684seq2seq\u63a5\u53e3\u662ftf.contrib.legacy_seq2seq\u4e0b\uff0c\u65b0\u7684\u63a5\u53e3\u5728tf.contrib.seq2seq\u4e0b\u3002\n\n\n\u65b0seq2seq\u63a5\u53e3\u4e0e\u65e7\u7684\u76f8\u6bd4\u6700\u4e3b\u8981\u7684\u533a\u522b\u662f\u5b83\u662f\u52a8\u6001\u5c55\u5f00\u7684\uff0c\u800c\u65e7\u7684\u662f\u9759\u6001\u5c55\u5f00\u7684\u3002\n\n\n\n\n\u9759\u6001\u5c55\u5f00(static unrolling) \uff1a\u6307\u7684\u662f\u5b9a\u4e49\u6a21\u578b\u521b\u5efagraph\u7684\u65f6\u5019\uff0c\u5e8f\u5217\u7684\u957f\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u4e4b\u540e\u4f20\u5165\u7684\u6240\u6709\u5e8f\u5217\u90fd\u5f97\u662f\u5b9a\u4e49\u65f6\u6307\u5b9a\u7684\u957f\u5ea6\u3002\u8fd9\u6837\u6240\u6709\u7684\u53e5\u5b50\u90fd\u8981padding\u5230\u6307\u5b9a\u7684\u957f\u5ea6\uff0c\u5f88\u6d6a\u8d39\u5b58\u50a8\u7a7a\u95f4\uff0c\u8ba1\u7b97\u6548\u7387\u4e5f\u4e0d\u9ad8\n\n\n\u52a8\u6001\u5c55\u5f00(dynamic unrolling)\uff1a\u4f7f\u7528\u63a7\u5236\u6d41ops\u5904\u7406\u5e8f\u5217\uff0c\u53ef\u4ee5\u4e0d\u9700\u8981\u4e8b\u5148\u6307\u5b9a\u597d\u5e8f\u5217\u957f\u5ea6\n\n\n\u4e0d\u7ba1\u9759\u6001\u8fd8\u662f\u52a8\u6001\uff0c\u8f93\u5165\u7684\u6bcf\u4e00\u4e2abatch\u5185\u7684\u5e8f\u5217\u957f\u5ea6\u90fd\u8981\u4e00\u6837\n\n\n\n\nin[4]: tf.__version__\nOut[4]: '1.5.0'\n\n\n\n\n\n\n_allowed_symbols = [\n    \"sequence_loss\",\n    \"Decoder\",\n    \"dynamic_decode\",\n    \"BasicDecoder\",\n    \"BasicDecoderOutput\",\n    \"BeamSearchDecoder\",\n    \"BeamSearchDecoderOutput\",\n    \"BeamSearchDecoderState\",\n    \"Helper\",\n    \"CustomHelper\",\n    \"FinalBeamSearchDecoderOutput\",\n    \"gather_tree\",\n    \"GreedyEmbeddingHelper\",\n    \"SampleEmbeddingHelper\",\n    \"ScheduledEmbeddingTrainingHelper\",\n    \"ScheduledOutputTrainingHelper\",\n    \"TrainingHelper\",\n    \"BahdanauAttention\",\n    \"LuongAttention\",\n    \"hardmax\",\n    \"AttentionWrapperState\",\n    \"AttentionWrapper\",\n    \"AttentionMechanism\",\n    \"tile_batch\"]\n\n\n\n\n\n\n\n\u719f\u6089\u8fd9\u4e9b\u63a5\u53e3\u6700\u597d\u7684\u65b9\u6cd5\u5c31\u662f\u9605\u8bfbAPI\u6587\u6863\uff0c\u7136\u540e\u4f7f\u7528\u5b83\u4eec\u3002\n\n\n1.1 \u7ecf\u5178\u7684seq2seq\u6a21\u578b\n\n\n\n\n\n\n\n\n\n\u56fe6:\u8bba\u6587[2] \u6a21\u578b\u7ed3\u6784\n\n\n\u8f93\u5165\u7684\u5e8f\u5217\u4e3a['A', 'B', 'C', '\n']\uff0c\u8f93\u51fa\u5e8f\u5217\u4e3a['W', 'X', 'Y', 'Z', '\n']\n\n\n\u8fd9\u91ccEncoder\u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u7f16\u7801\uff0c\u5c06\u6700\u540e\u4e00\u65f6\u523b\u8f93\u51fa\u7684hidden state(\u4e0b\u6587\u7684final state)\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u7f16\u7801\u5411\u91cf\u3002\nDecoder\u5c06\u7ec8\u6b62\u7b26\n\u4f5c\u4e3a\u521d\u59cb\u8f93\u5165(\u4e5f\u53ef\u4ee5\u4f7f\u7528\u5176\u4ed6\u7b26\u53f7\u5982\n\u7b49)\uff0cEncoder\u7684final state\u4f5c\u4e3a\u521d\u59cb\u72b6\u6001\uff0c\u7136\u540e\u751f\u6210\u5e8f\u5217\u76f4\u5230\u9047\u4e0a\u7ec8\u6b62\u7b26\n\u3002\n\n\n\u7ed3\u6784\u5f88\u7b80\u5355\uff0c\u53ea\u8981\u5b9e\u73b0Encoder\u4e0eDecoder\u518d\u5c06\u4ed6\u4eec\u4e32\u8d77\u6765\u5373\u53ef\u3002\n\n\n\u8bba\u6587[2]\u4e2d\u7684Encoder\u4f7f\u7528\u7684\u662f\u4e00\u4e2a4\u5c42\u7684\u5355\u5411LSTM\uff0c\u8fd9\u4e00\u90e8\u5206\u4f7f\u7528RNN\u7684\u63a5\u53e3\u5373\u53ef\uff0c\u8fd8\u4e0d\u9700\u8981\u7528\u5230Seq2Seq\u4e2d\u7684\u63a5\u53e3\u3002\u7b2c\u4e00\u5f20\u56fe\u4e2d\u7684\u6a21\u578b\u6846\u67b6\u867d\u7136\u9610\u8ff0\u6e05\u695a\u4e86Encoder-Decoder\u8fd9\u79cd\u67b6\u6784\uff0c\u4f46\u662f\u5177\u4f53\u5b9e\u73b0\u4e0a\uff0c\u4e0d\u662f\u76f4\u63a5\u5c06\u5e8f\u5217['A', 'B', 'C', '\n']\u8f93\u5165\u5230Encoder\u4e2d\uff0cEncoder\u7684\u5b8c\u6574\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\n\n---------------------Encoder----------------\n\n\n\n\n\n\n\n\n\n\u56fe8:Encoder\u7ed3\u6784\n\n\n\n\n\n\ninput\n\uff1a\u4e0d\u662f\u539f\u59cb\u7684\u5e8f\u5217\uff0c\u800c\u662f\u5c06\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u8f6c\u6362\u4e3a\u5b57\u5178\u4e2d\u5bf9\u5e94\u7684id\u3002\u4e0d\u7ba1\u662ftrain\u8fd8\u662finference\u9636\u6bb5\uff0c\u4e3a\u4e86\u6548\u7387\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u4e2amini-batch\uff0c\u6240\u4ee5\u9700\u8981\u4e3ainput\u5b9a\u4e49\u4e00\u4e2aint\u578brank=2\u7684placeholder\u3002\n\n\n\n\n\n\nembedding\n\uff1a\u5b9a\u4e49\u4e3atrainable=True\u7684\u53d8\u91cf\uff0c\u8fd9\u6837\u5373\u4f7f\u4f7f\u7528pre-trained\u7684\u8bcd\u5411\u91cf\u4e5f\u53ef\u4ee5\u5728\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u7a0b\u4e2d\u8c03\u4f18\u3002\n\n\n\n\n\n\nMultiLayer_LSTM\n\uff1a\u63a5\u6536\u7684\u8f93\u5165\u662f\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\u3002\n\n\n\n\n\n\n\u5176\u4e2d\uff0ctf.nn.dynamic_rnn\u65b9\u6cd5\u63a5\u6536encoder\u5b9e\u4f8b\u4ee5\u53caembbeded\u5411\u91cf\u4e4b\u540e\uff0c\u5c31\u4f1a\u8f93\u51fa\u5305\u542b\u6bcf\u4e2a\u65f6\u523bhidden state\u7684outputs\u4ee5\u53cafinal state\uff0c\u5982\u679c\u521d\u59cb\u72b6\u6001\u4e3a0\u7684\u8bdd\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u58f0\u660ezero_state\u518d\u5c06\u5176\u4f5c\u4e3a\u53c2\u6570\u4f20\u5165\uff0c\u53ea\u9700\u8981\u6307\u5b9astate\u7684dtype\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u4e2d\u4f1a\u5c06\u521d\u59cb\u72b6\u6001\u81ea\u52a8\u521d\u59cb\u5316\u4e3a0\u5411\u91cf\n\n\n------------------Decoder----------------------\n\n\n\n\n\n\n\n\n\n\u56fe9:Encoder\u7ed3\u6784\n\n\n\n\n\n\ninput\n\uff1a\u4e0eencoder\u7684\u4e00\u6837\uff0c\u4e5f\u662f\u5e8f\u5217\u5143\u7d20\u5bf9\u5e94\u7684id\u3002\n\n\n\n\n\n\nembedding\n\uff1a\u89c6\u60c5\u51b5\u800c\u5b9a\u9700\u4e0d\u9700\u8981\u4e0eencoder\u7684embedding\u4e0d\u540c\uff0c\u6bd4\u5982\u5728\u7ffb\u8bd1\u4e2d\uff0c\u6e90\u8bed\u8a00\u4e0e\u76ee\u6807\u8bed\u8a00\u7684\u8bcd\u5411\u91cf\u7a7a\u95f4\u5c31\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u50cf\u6587\u672c\u6458\u8981\u8fd9\u79cd\u90fd\u662f\u57fa\u4e8e\u4e00\u79cd\u8bed\u8a00\u7684\uff0cencoder\u4e0edecoder\u7684embedding matrix\u662f\u53ef\u4ee5\u5171\u7528\u7684\u3002\n\n\n\n\n\n\nDense_Layer\n\uff1a\u4e0eencoder\u4ec5\u8f93\u51fahidden state\u4e0d\u540c\uff0cdecoder\u9700\u8981\u8f93\u51fa\u6bcf\u4e2a\u65f6\u523b\u8bcd\u5178\u4e2d\u5404token\u7684\u6982\u7387\uff0c\u56e0\u6b64\u8fd8\u9700\u8981\u4e00\u4e2adense layer\u5c06hidden state\u5411\u91cf\u8f6c\u6362\u4e3a\u7ef4\u5ea6\u7b49\u4e8evocabulary_size\u7684\u5411\u91cf\uff0c\u7136\u540e\u518d\u5c06dense layer\u8f93\u51fa\u7684logits\u7ecf\u8fc7softmax\u5c42\u5f97\u5230\u6700\u7ec8\u7684token\u6982\u7387\u3002\n\n\n\n\n\n\nDecoder\n\u7684\u5b9a\u4e49\u9700\u8981\u533a\u5206inference\u9636\u6bb5\u8fd8\u662ftrain\u9636\u6bb5\u3002\n\n\n\n\n\n\ninference\u9636\u6bb5\uff0cdecoder\u7684\u8f93\u51fa\u662f\u672a\u77e5\u7684\uff0c\u5bf9\u4e8e\u751f\u6210['W', 'X', 'Y', 'Z', '\n']\u5e8f\u5217\uff0c\u662f\u5728decoder\u8f93\u51fatoken 'W'\u4e4b\u540e\uff0c\u518d\u5c06'W'\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ed3\u5408\u6b64\u65f6\u7684hidden state\uff0c\u63a8\u65ad\u51fa\u4e0b\u4e00\u4e2atoken 'X'\uff0c\u4ee5\u6b64\u7c7b\u63a8\u76f4\u5230\u8f93\u51fa\u4e3a\n\u6216\u8fbe\u5230\u6700\u957f\u5e8f\u5217\u957f\u5ea6\u4e4b\u540e\u7ec8\u6b62\u3002\n\n\n\n\n\n\n\u800c\u5728train\u9636\u6bb5\uff0cdecoder\u5e94\u8be5\u8f93\u51fa\u7684\u5e8f\u5217\u662f\u5df2\u77e5\u7684\uff0c\u4e0d\u7ba1\u6700\u7ec8output\u7684\u7ed3\u679c\u662f\u4ec0\u4e48\uff0c\u90fd\u5c06\u5df2\u77e5\u5e8f\u5217\u4e2d\u7684token\u4f9d\u6b21\u8f93\u5165\u3002train\u7684\u9636\u6bb5\u5982\u679c\u4e5f\u5c06\u8f93\u51fa\u7684\u7ed3\u679c\u518d\u4f5c\u4e3a\u8f93\u5165\uff0c\u4e00\u65e6\u524d\u9762\u7684\u4e00\u6b65\u9519\u4e86\uff0c\u90fd\u4f1a\u653e\u5927\u8bef\u5dee\uff0c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u4e0d\u7a33\u5b9a\u3002\n\n\n\n\n\n\ndecoder\u5c06\u7528\u5230seq2seq\u4e2d\u7684TrainingHelper, GreedyEmbeddingHelper, BasicDecoder\u4e09\u4e2a\u7c7b\uff0c\u4ee5\u53cadynamic_decode\u65b9\u6cd5\uff0c\u8fd8\u5c06\u7528\u5230tensorflow.python.layers.core\u4e0b\u7684Dense\u7c7b\u3002\n\n\n\n\n\n\n1.BasicDecoder\n\n\n\u5b9e\u73b0decoder\u6700\u5148\u5173\u6ce8\u5230\u7684\u5c31\u662fBasicDecoder\uff0c\u5b83\u7684\u6784\u9020\u51fd\u6570\u4e0e\u53c2\u6570\u7684\u5b9a\u4e49\u5982\u4e0b\uff1a\n\n\n\n__init__( cell, helper, initial_state, output_layer=None ) \n- cell: An RNNCell instance. \n- helper: A Helper instance. \n- initial_state: A (possibly nested tuple of\u2026) tensors and TensorArrays. The initial state of the RNNCell. \n- output_layer: (Optional) An instance of tf.layers.Layer, i.e., tf.layers.Dense. Optional layer to apply to the RNN output prior to storing the result or sampling.\n\n\n\n\n\n\n\n\ncell\n\uff1a\u5728\u8fd9\u91cc\u5c31\u662f\u4e00\u4e2a\u591a\u5c42LSTM\u7684\u5b9e\u4f8b\uff0c\u4e0e\u5b9a\u4e49encoder\u65f6\u65e0\u5f02 \n\n\n\n\n\n\nhelper\n\uff1a\u8fd9\u91cc\u53ea\u662f\u7b80\u5355\u8bf4\u660e\u662f\u4e00\u4e2aHelper\u5b9e\u4f8b\uff0c\u7b2c\u4e00\u6b21\u770b\u6587\u6863\u7684\u65f6\u5019\u80af\u5b9a\u8fd8\u4e0d\u77e5\u9053\u8fd9\u4e2aHelper\u662f\u4ec0\u4e48\uff0c\u4e0d\u7528\u7740\u6025\uff0c\u770b\u5230\u5177\u4f53\u7684Helper\u5b9e\u4f8b\u5c31\u660e\u767d\u4e86 \n\n\n\n\n\n\ninitial_state\n\uff1aencoder\u7684final state\uff0c\u7c7b\u578b\u8981\u4e00\u81f4\uff0c\u4e5f\u5c31\u662f\u8bf4\u5982\u679cencoder\u7684final state\u662ftuple\u7c7b\u578b(\u5982LSTM\u7684\u5305\u542b\u4e86cell state\u4e0ehidden state)\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684\u8f93\u5165\u4e5f\u5fc5\u987b\u662ftuple\u3002\u76f4\u63a5\u5c06encoder\u7684final_state\u4f5c\u4e3a\u8fd9\u4e2a\u53c2\u6570\u8f93\u5165\u5373\u53ef \n\n\n\n\n\n\noutput_layer\n\uff1a\u5bf9\u5e94\u7684\u5c31\u662f\u6846\u67b6\u56fe\u4e2d\u7684Dense_Layer\uff0c\u53ea\u4e0d\u8fc7\u6587\u6863\u91cc\u5199tf.layers.Dense\uff0c\u4f46\u662ftf.layers\u4e0b\u53ea\u6709dense\u65b9\u6cd5\uff0cDense\u7684\u5b9e\u4f8b\u8fd8\u9700\u8981from tensorflow.python.layers.core import Dense\u3002\n\n\n\n\n\n\nBasicDecoder\u7684\u4f5c\u7528\u5c31\u662f\u5b9a\u4e49\u4e00\u4e2a\u5c01\u88c5\u4e86decoder\u5e94\u8be5\u6709\u7684\u529f\u80fd\u7684\u5b9e\u4f8b\uff0c\u6839\u636eHelper\u5b9e\u4f8b\u7684\u4e0d\u540c\uff0c\u8fd9\u4e2adecoder\u53ef\u4ee5\u5b9e\u73b0\u4e0d\u540c\u7684\u529f\u80fd\uff0c\u6bd4\u5982\u5728train\u7684\u9636\u6bb5\uff0c\u4e0d\u628a\u8f93\u51fa\u91cd\u65b0\u4f5c\u4e3a\u8f93\u5165\uff0c\u800c\u5728inference\u9636\u6bb5\uff0c\u5c06\u8f93\u51fa\u63a5\u5230\u8f93\u5165\u3002\n\n\n2.TrainingHelper\n\n\n\u6784\u9020\u51fd\u6570\u4e0e\u53c2\u6570\u5982\u4e0b\uff1a\n\n\n__init__( inputs, sequence_length, time_major=False, name=None ) \n- inputs: A (structure of) input tensors. \n- sequence_length: An int32 vector tensor. \n- time_major: Python bool. Whether the tensors in inputs are time major. If False (default), they are assumed to be batch major. \n- name: Name scope for any created operations.\n\n\n\n\n\n\n\n\ninputs\n\uff1a\u5bf9\u5e94Decoder\u6846\u67b6\u56fe\u4e2d\u7684embedded_input\uff0ctime_major=False\u7684\u65f6\u5019\uff0cinputs\u7684shape\u5c31\u662f[batch_size, sequence_length, embedding_size] \uff0ctime_major=True\u65f6\uff0cinputs\u7684shape\u4e3a[sequence_length, batch_size, embedding_size] \n\n\n\n\n\n\nsequence_length\n\uff1a\u8fd9\u4e2a\u6587\u6863\u5199\u7684\u592a\u7b80\u7565\u4e86\uff0c\u4e0d\u8fc7\u5728\u6e90\u7801\u4e2d\u53ef\u4ee5\u770b\u51fa\u6307\u7684\u662f\u5f53\u524dbatch\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u7684\u957f\u5ea6(self._batch_size = array_ops.size(sequence_length))\u3002 \n\n\n\n\n\n\ntime_major\n\uff1a\u51b3\u5b9ainputs Tensor\u524d\u4e24\u4e2adim\u8868\u793a\u7684\u542b\u4e49 \nname\uff1a\u5982\u6587\u6863\u6240\u8ff0\n\n\n\n\n\n\nTrainingHelper\u7528\u4e8etrain\u9636\u6bb5\uff0cnext_inputs\u65b9\u6cd5\u4e00\u6837\u4e5f\u63a5\u6536outputs\u4e0esample_ids\uff0c\u4f46\u662f\u53ea\u662f\u4ece\u521d\u59cb\u5316\u65f6\u7684inputs\u8fd4\u56de\u4e0b\u4e00\u65f6\u523b\u7684\u8f93\u5165\u3002\n\n\n3.GreedyEmbeddingHelper\n\n\n__init__( embedding, start_tokens, end_token ) \n- embedding: A callable that takes a vector tensor of ids (argmax ids), or the params argument for embedding_lookup. The returned tensor will be passed to the decoder input. \n- start_tokens: int32 vector shaped [batch_size], the start tokens. \n- end_token: int32 scalar, the token that marks end of decoding.\n\nA helper for use during inference. \nUses the argmax of the output (treated as logits) and passes the result through an embedding layer to get the next input.\n\n\n\n\n\n\u5b98\u65b9\u6587\u6863\u5df2\u7ecf\u8bf4\u660e\uff0c\u8fd9\u662f\u7528\u4e8einference\u9636\u6bb5\u7684helper\uff0c\u5c06output\u8f93\u51fa\u540e\u7684logits\u4f7f\u7528argmax\u83b7\u5f97id\u518d\u7ecf\u8fc7embedding layer\u6765\u83b7\u53d6\u4e0b\u4e00\u65f6\u523b\u7684\u8f93\u5165\u3002\n\n\n\n\nembedding\n\uff1aparams argument for embedding_lookup\uff0c\u4e5f\u5c31\u662f \u5b9a\u4e49\u7684embedding \u53d8\u91cf\u4f20\u5165\u5373\u53ef\u3002 \n\n\nstart_tokens\n\uff1a batch\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u8d77\u59cb\u8f93\u5165\u7684token_id \n\n\nend_token\n\uff1a\u5e8f\u5217\u7ec8\u6b62\u7684token_id\n\n\n\n\n4.dynamic_decode\n\n\ndynamic_decode( decoder, output_time_major=False, impute_finished=False, maximum_iterations=None, parallel_iterations=32, swap_memory=False, scope=None)\n\n\n\n\n\u8fd9\u4e2a\u65b9\u6cd5\u5f88\u76f4\u89c2\uff0c\u5c06\u5b9a\u4e49\u597d\u7684decoder\u5b9e\u4f8b\u4f20\u5165\uff0c\u5176\u4ed6\u51e0\u4e2a\u53c2\u6570\u6587\u6863\u4ecb\u7ecd\u7684\u5f88\u6e05\u695a\u3002\u5f88\u503c\u5f97\u5b66\u4e60\u7684\u662f\u5176\u4e2d\u5982\u4f55\u4f7f\u7528control flow ops\u6765\u5b9e\u73b0dynamic\u7684\u8fc7\u7a0b\u3002\n\n\n------------------\u4ee3\u7801--------------------\n\n\n\u7efc\u5408\u4f7f\u7528\u4e0a\u8ff0\u63a5\u53e3\u5b9e\u73b0\u57fa\u672cEncoder-Decoder\u6a21\u578b\u7684\u4ee3\u7801\u5982\u4e0b\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib.seq2seq import *\nfrom tensorflow.python.layers.core import Dense\n\n\nclass Seq2SeqModel(object):\n\n    def __init__(self, rnn_size, layer_size, encoder_vocab_size, \n        decoder_vocab_size, embedding_dim, grad_clip, is_inference=False):\n        # define inputs\n        self.input_x = tf.placeholder(tf.int32, shape=[None, None], name='input_ids')\n\n        # define embedding layer\n        with tf.variable_scope('embedding'):\n            encoder_embedding = tf.Variable(tf.truncated_normal(shape=[encoder_vocab_size, embedding_dim], stddev=0.1), \n                name='encoder_embedding')\n            decoder_embedding = tf.Variable(tf.truncated_normal(shape=[decoder_vocab_size, embedding_dim], stddev=0.1),\n                name='decoder_embedding')\n\n        # define encoder\n        with tf.variable_scope('encoder'):\n            encoder = self._get_simple_lstm(rnn_size, layer_size)\n\n        with tf.device('/cpu:0'):\n            input_x_embedded = tf.nn.embedding_lookup(encoder_embedding, self.input_x)\n\n        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder, input_x_embedded, dtype=tf.float32)\n\n        # define helper for decoder\n        if is_inference:\n            self.start_tokens = tf.placeholder(tf.int32, shape=[None], name='start_tokens')\n            self.end_token = tf.placeholder(tf.int32, name='end_token')\n            helper = GreedyEmbeddingHelper(decoder_embedding, self.start_tokens, self.end_token)\n        else:\n            self.target_ids = tf.placeholder(tf.int32, shape=[None, None], name='target_ids')\n            self.decoder_seq_length = tf.placeholder(tf.int32, shape=[None], name='batch_seq_length')\n            with tf.device('/cpu:0'):\n                target_embeddeds = tf.nn.embedding_lookup(decoder_embedding, self.target_ids)\n            helper = TrainingHelper(target_embeddeds, self.decoder_seq_length)\n\n        with tf.variable_scope('decoder'):\n            fc_layer = Dense(decoder_vocab_size)\n            decoder_cell = self._get_simple_lstm(rnn_size, layer_size)\n            decoder = BasicDecoder(decoder_cell, helper, encoder_state, fc_layer)\n\n        logits, final_state, final_sequence_lengths = dynamic_decode(decoder)\n\n        if not is_inference:\n            targets = tf.reshape(self.target_ids, [-1])\n            logits_flat = tf.reshape(logits.rnn_output, [-1, decoder_vocab_size])\n            print ('shape logits_flat:{}'.format(logits_flat.shape))\n            print ('shape logits:{}'.format(logits.rnn_output.shape))\n\n            self.cost = tf.losses.sparse_softmax_cross_entropy(targets, logits_flat)\n\n            # define train op\n            tvars = tf.trainable_variables()\n            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), grad_clip)\n\n            optimizer = tf.train.AdamOptimizer(1e-3)\n            self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n        else:\n            self.prob = tf.nn.softmax(logits)\n\n    def _get_simple_lstm(self, rnn_size, layer_size):\n        lstm_layers = [tf.contrib.rnn.LSTMCell(rnn_size) for _ in xrange(layer_size)]\n        return tf.contrib.rnn.MultiRNNCell(lstm_layers)\n\n\n\n\n\n\n---------------\u5b9e\u4f8b----------------\n\n\n\n\u968f\u673a\u5e8f\u5217\u751f\u6210\u5668\ndef random_sequences(length_from, length_to, vocab_lower, vocab_upper, batch_size):\n    def random_length():\n        if length_from == length_to:\n            return length_from\n        return np.random.randint(length_from, length_to + 1)\n\n    while True:\n        yield [\n            np.random.randint(low=vocab_lower, high=vocab_upper, size=random_length()).tolist()\n            for _ in range(batch_size)\n            ]\n\n\n\n\n\u6784\u5efa\u4e00\u4e2a\u968f\u673a\u5e8f\u5217\u751f\u6210\u5668\u65b9\u4fbf\u540e\u9762\u751f\u6210\u5e8f\u5217\uff0c\u5176\u4e2d length_from \u548c length_to\u8868\u793a\u5e8f\u5217\u7684\u957f\u5ea6\u8303\u56f4\u4ece\u591a\u5c11\u5230\u591a\u5c11\uff0cvocab_lower \u548c vocab_upper \u8868\u793a\u751f\u6210\u7684\u5e8f\u5217\u503c\u7684\u8303\u56f4\u4ece\u591a\u5c11\u5230\u591a\u5c11\uff0cbatch_size \u5373\u662f\u6279\u7684\u6570\u91cf\u3002\n\n\n\n\n\n\u586b\u5145\u5e8f\u5217\ndef make_batch(inputs, max_sequence_length=None):\n    sequence_lengths = [len(seq) for seq in inputs]\n    batch_size = len(inputs)\n    if max_sequence_length is None:\n        max_sequence_length = max(sequence_lengths)\n    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32)\n    for i, seq in enumerate(inputs):\n        for j, element in enumerate(seq):\n            inputs_batch_major[i, j] = element\n    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n    return inputs_time_major, sequence_lengths\n\n\n\n\n\n\u751f\u6210\u7684\u968f\u673a\u5e8f\u5217\u7684\u957f\u5ea6\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u9700\u8981\u5bf9\u77ed\u7684\u5e8f\u5217\u7528\u6765\u586b\u5145\uff0c\u800c\u53ef\u8bbe\u4e3a0\uff0c\u53d6\u6700\u957f\u7684\u5e8f\u5217\u4f5c\u4e3a\u6bcf\u4e2a\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u4e0d\u8db3\u7684\u586b\u5145\uff0c\u7136\u540e\u518d\u8f6c\u6362\u6210time major\u5f62\u5f0f\u3002\n\n\n\u6784\u5efa\u56fe\nencoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\necoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\ndecoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n\n\n\n\n\u521b\u5efa\u4e09\u4e2a\u5360\u4f4d\u7b26\uff0c\u5206\u522b\u4e3aencoder\u7684\u8f93\u5165\u5360\u4f4d\u7b26\u3001decoder\u7684\u8f93\u5165\u5360\u4f4d\u7b26\u548cdecoder\u7684target\u5360\u4f4d\u7b26\u3002\n\n\nembeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\nencoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n\n\n\n\n\u5c06encoder\u548cdecoder\u7684\u8f93\u5165\u505a\u4e00\u4e2a\u5d4c\u5165\u64cd\u4f5c\uff0c\u5bf9\u4e8e\u5927\u8bcd\u6c47\u91cf\u8fd9\u4e2a\u80fd\u8fbe\u5230\u964d\u7ef4\u7684\u6548\u679c\uff0c\u5d4c\u5165\u64cd\u4f5c\u4e5f\u662f\u5f88\u5e38\u7528\u7684\u65b9\u5f0f\u4e86\u3002\u5728seq2seq\u6a21\u578b\u4e2d\uff0cencoder\u548cdecoder\u90fd\u662f\u5171\u7528\u4e00\u4e2a\u5d4c\u5165\u5c42\u5373\u53ef\u3002\u5d4c\u5165\u5c42\u7684\u5411\u91cf\u5f62\u72b6\u4e3a[vocab_size, input_embedding_size]\uff0c\u521d\u59cb\u503c\u4ece-1\u52301\uff0c\u540e\u9762\u8bad\u7ec3\u4f1a\u81ea\u52a8\u8c03\u6574\u3002\n\n\nencoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\nencoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n        encoder_cell, encoder_inputs_embedded,\n        dtype=tf.float32, time_major=True,\n    )\ndecoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\ndecoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n        decoder_cell, decoder_inputs_embedded,\n        initial_state=encoder_final_state,\n        dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n    )\n\n\n\n\n\n\u521b\u5efaencoder\u548cdecoder\u7684LSTM\u795e\u7ecf\u7f51\u7edc\uff0cencoder_hidden_units \u4e3aLSTM\u9690\u5c42\u6570\u91cf\uff0c\u8bbe\u5b9a\u8f93\u5165\u683c\u5f0f\u4e3atime major\u683c\u5f0f\u3002\u8fd9\u91cc\u6211\u4eec\u4e0d\u5173\u5fc3encoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u6211\u4eec\u8981\u7684\u662f\u5b83\u7684\u6700\u7ec8\u72b6\u6001encoder_final_state\uff0c\u5c06\u5176\u4f5c\u4e3adecoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u521d\u59cb\u72b6\u6001\u3002\n\n\ndecoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\ndecoder_prediction = tf.argmax(decoder_logits, 2)\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n        logits=decoder_logits,\n    )\nloss = tf.reduce_mean(stepwise_cross_entropy)\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\n\n\n\n\u5bf9\u4e8edecoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u6211\u4eec\u8981\u4e00\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c\u6240\u4ee5\u9700\u8981\u4e00\u4e2a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff0c\u8f93\u51fa\u5c42\u795e\u7ecf\u5143\u6570\u91cf\u662f\u8bcd\u6c47\u7684\u6570\u91cf\u3002\u8f93\u51fa\u5c42\u6700\u5927\u503c\u5bf9\u5e94\u7684\u795e\u7ecf\u5143\u5373\u4e3a\u9884\u6d4b\u7684\u7c7b\u522b\u3002\u8f93\u51fa\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570\u7528softmax\uff0c\u635f\u5931\u51fd\u6570\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u3002\n\n\n\u521b\u5efa\u4f1a\u8bdd\nwith tf.Session(graph=train_graph) as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(epochs):\n        batch = next(batches)\n        encoder_inputs_, _ = make_batch(batch)\n        decoder_targets_, _ = make_batch([(sequence) + [EOS] for sequence in batch])\n        decoder_inputs_, _ = make_batch([[EOS] + (sequence) for sequence in batch])\n        feed_dict = {encoder_inputs: encoder_inputs_, decoder_inputs: decoder_inputs_,\n                     decoder_targets: decoder_targets_,\n                     }\n        _, l = sess.run([train_op, loss], feed_dict)\n        loss_track.append(l)\n        if epoch == 0 or epoch % 1000 == 0:\n            print('loss: {}'.format(sess.run(loss, feed_dict)))\n            predict_ = sess.run(decoder_prediction, feed_dict)\n            for i, (inp, pred) in enumerate(zip(feed_dict[encoder_inputs].T, predict_.T)):\n                print('input > {}'.format(inp))\n                print('predicted > {}'.format(pred))\n                if i >= 20:\n                    break\n\n\n\n\n\n\u521b\u5efa\u4f1a\u8bdd\u5f00\u59cb\u6267\u884c\uff0c\u6bcf\u6b21\u751f\u6210\u4e00\u6279\u6570\u91cf\uff0c\u7528 make_batch \u5206\u522b\u521b\u5efaencoder\u8f93\u5165\u3001decoder\u7684target\u548cdecoder\u7684\u8f93\u5165\u3002\u5176\u4e2dtarget\u9700\u8981\u5728\u540e\u9762\u52a0\u4e0a[EOS]\uff0c\u5b83\u8868\u793a\u53e5\u5b50\u7684\u7ed3\u5c3e\uff0c\u540c\u65f6\u8f93\u5165\u4e5f\u52a0\u4e0a[EOS]\u8868\u793a\u7f16\u7801\u5f00\u59cb\u3002\u6bcf\u8bad\u7ec31000\u8bcd\u8f93\u51fa\u770b\u770b\u6548\u679c\u3002\n\n\n1.2 Attention Seq2Seq\u6a21\u578b\n\n\n\u4e0b\u9762\u6211\u4eec\u68b3\u7406\u4e00\u4e0b\u5e26Attention\u7684seq2seq\u7684\u7ed3\u6784\n\n\n-------------Bi-RNN Encoder-----------------------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n----------------Attention-Decoder------------------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u8be6\u7ec6\u7684\u5206\u6790\u53ef\u4ee5\u53c2\u89c1\u53c2\u8003\u6587\u732e\u30108\u3011\u3002\n\n\n1.3 tf-seq2seq\u5f00\u6e90\u6846\u67b6\n\n\n2017\u5e744\u670811\u65e5\uff0cGoogle\u7684\u5927\u8111\u7814\u7a76\u56e2\u961f\u53d1\u5e03\u4e86 tf-seq2seq\u8fd9\u4e2a\u5f00\u6e90\u7684TensorFlow\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u8f7b\u6613\u8fdb\u884c\u5b9e\u9a8c\u800c\u8fbe\u5230\u73b0\u6709\u7684\u6548\u679c\uff0c\u56e2\u961f\u5236\u4f5c\u4e86\u8be5\u6846\u67b6\u7684\u4ee3\u7801\u5e93\u548c\u6a21\u5757\u7b49\uff0c\u80fd\u591f\u6700\u597d\u5730\u652f\u6301\u5176\u529f\u80fd\u3002\u53bb\u5e74\uff0c\u8be5\u56e2\u961f\u53d1\u5e03\u4e86Google\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\uff08GoogleNeural Machine Translation\uff0cGNMT\uff09\uff0c\u5b83\u662f\u4e00\u4e2a\u5e8f\u5217\u5230\u5e8f\u5217sequence-to-sequence\uff08\u201cseq2seq\u201d\uff09\u7684\u6a21\u578b\uff0c\u76ee\u524d\u7528\u4e8eGoogle\u7ffb\u8bd1\u7cfb\u7edf\u4e2d\u3002\u867d\u7136GNMT\u5728\u7ffb\u8bd1\u8d28\u91cf\u4e0a\u6709\u957f\u8db3\u7684\u8fdb\u6b65\uff0c\u4f46\u662f\u5b83\u8fd8\u662f\u53d7\u9650\u4e8e\u8bad\u7ec3\u7684\u6846\u67b6\u65e0\u6cd5\u5bf9\u5916\u90e8\u7814\u7a76\u4eba\u5458\u5f00\u653e\u7684\u77ed\u677f\u3002\n\n\n2.keras\u5b9e\u73b0seq2seq\n\n\n\u5728\u5b98\u65b9\u7684keras\u5b9e\u4f8b\u4e2d\u6709\u5b8c\u6574\u7684seq2seq,\u53ef\u4ee5\u53c2\u8003\u53c2\u8003\u6587\u732e\u30109\u3011\u3002\n\n\n3.\u53c2\u8003\u6587\u732e\n\n\n[1] \nhttps://google.github.io/seq2seq/\n\n\n[2] \nhttps://github.com/DataXujing/seq2seq\n\n\n[3] \nhttps://www.w3cschool.cn/tensorflow_python/tensorflow_python-i8jh28vt.html\n\n\n[4] \nhttp://www.tensorfly.cn/\n\n\n[5] \nhttp://blog.csdn.net/thriving_fcl/article/details/74165062\n\n\n[6] \nhttp://blog.csdn.net/wangyangzhizhou/article/details/77977655\n\n\n[7] \nhttps://www.bilibili.com/video/av12005043/\n\n\n[8] \nhttp://blog.csdn.net/thriving_fcl/article/details/74853556\n\n\n[9] \nhttps://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py",
            "title": "seq2seq\u6a21\u578b\u7684python\u5b9e\u73b0"
        },
        {
            "location": "/chapter3/#seq2seqpython",
            "text": "\u672c\u8282\u4e3b\u8981\u8bb2\u89e3\u5982\u4f55\u7528tensorflow\u53cakeras\u5b9e\u73b0seq2seq2\u6a21\u578b\uff0c\u6211\u4eec\u540e\u671f\u7684\u8054\u4fe1\u6587\u672c\u804a\u5929\u673a\u5668\u4eba\u7684\u4e3b\u8981\u8bad\u7ec3\u6a21\u578b\u5c31\u91c7\u7528seq2seq   1.tensorflow\u5b9e\u73b0seq2seq  Tensorflow 1.0.0 \u7248\u672c\u4ee5\u540e\uff0c\u5f00\u53d1\u4e86\u65b0\u7684seq2seq\u63a5\u53e3\uff0c\u5f03\u7528\u4e86\u539f\u6765\u7684\u63a5\u53e3\u3002\u65e7\u7684seq2seq\u63a5\u53e3\u662ftf.contrib.legacy_seq2seq\u4e0b\uff0c\u65b0\u7684\u63a5\u53e3\u5728tf.contrib.seq2seq\u4e0b\u3002  \u65b0seq2seq\u63a5\u53e3\u4e0e\u65e7\u7684\u76f8\u6bd4\u6700\u4e3b\u8981\u7684\u533a\u522b\u662f\u5b83\u662f\u52a8\u6001\u5c55\u5f00\u7684\uff0c\u800c\u65e7\u7684\u662f\u9759\u6001\u5c55\u5f00\u7684\u3002   \u9759\u6001\u5c55\u5f00(static unrolling) \uff1a\u6307\u7684\u662f\u5b9a\u4e49\u6a21\u578b\u521b\u5efagraph\u7684\u65f6\u5019\uff0c\u5e8f\u5217\u7684\u957f\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u4e4b\u540e\u4f20\u5165\u7684\u6240\u6709\u5e8f\u5217\u90fd\u5f97\u662f\u5b9a\u4e49\u65f6\u6307\u5b9a\u7684\u957f\u5ea6\u3002\u8fd9\u6837\u6240\u6709\u7684\u53e5\u5b50\u90fd\u8981padding\u5230\u6307\u5b9a\u7684\u957f\u5ea6\uff0c\u5f88\u6d6a\u8d39\u5b58\u50a8\u7a7a\u95f4\uff0c\u8ba1\u7b97\u6548\u7387\u4e5f\u4e0d\u9ad8  \u52a8\u6001\u5c55\u5f00(dynamic unrolling)\uff1a\u4f7f\u7528\u63a7\u5236\u6d41ops\u5904\u7406\u5e8f\u5217\uff0c\u53ef\u4ee5\u4e0d\u9700\u8981\u4e8b\u5148\u6307\u5b9a\u597d\u5e8f\u5217\u957f\u5ea6  \u4e0d\u7ba1\u9759\u6001\u8fd8\u662f\u52a8\u6001\uff0c\u8f93\u5165\u7684\u6bcf\u4e00\u4e2abatch\u5185\u7684\u5e8f\u5217\u957f\u5ea6\u90fd\u8981\u4e00\u6837   in[4]: tf.__version__\nOut[4]: '1.5.0'  \n_allowed_symbols = [\n    \"sequence_loss\",\n    \"Decoder\",\n    \"dynamic_decode\",\n    \"BasicDecoder\",\n    \"BasicDecoderOutput\",\n    \"BeamSearchDecoder\",\n    \"BeamSearchDecoderOutput\",\n    \"BeamSearchDecoderState\",\n    \"Helper\",\n    \"CustomHelper\",\n    \"FinalBeamSearchDecoderOutput\",\n    \"gather_tree\",\n    \"GreedyEmbeddingHelper\",\n    \"SampleEmbeddingHelper\",\n    \"ScheduledEmbeddingTrainingHelper\",\n    \"ScheduledOutputTrainingHelper\",\n    \"TrainingHelper\",\n    \"BahdanauAttention\",\n    \"LuongAttention\",\n    \"hardmax\",\n    \"AttentionWrapperState\",\n    \"AttentionWrapper\",\n    \"AttentionMechanism\",\n    \"tile_batch\"]  \u719f\u6089\u8fd9\u4e9b\u63a5\u53e3\u6700\u597d\u7684\u65b9\u6cd5\u5c31\u662f\u9605\u8bfbAPI\u6587\u6863\uff0c\u7136\u540e\u4f7f\u7528\u5b83\u4eec\u3002  1.1 \u7ecf\u5178\u7684seq2seq\u6a21\u578b     \u56fe6:\u8bba\u6587[2] \u6a21\u578b\u7ed3\u6784  \u8f93\u5165\u7684\u5e8f\u5217\u4e3a['A', 'B', 'C', ' ']\uff0c\u8f93\u51fa\u5e8f\u5217\u4e3a['W', 'X', 'Y', 'Z', ' ']  \u8fd9\u91ccEncoder\u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u7f16\u7801\uff0c\u5c06\u6700\u540e\u4e00\u65f6\u523b\u8f93\u51fa\u7684hidden state(\u4e0b\u6587\u7684final state)\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u7f16\u7801\u5411\u91cf\u3002\nDecoder\u5c06\u7ec8\u6b62\u7b26 \u4f5c\u4e3a\u521d\u59cb\u8f93\u5165(\u4e5f\u53ef\u4ee5\u4f7f\u7528\u5176\u4ed6\u7b26\u53f7\u5982 \u7b49)\uff0cEncoder\u7684final state\u4f5c\u4e3a\u521d\u59cb\u72b6\u6001\uff0c\u7136\u540e\u751f\u6210\u5e8f\u5217\u76f4\u5230\u9047\u4e0a\u7ec8\u6b62\u7b26 \u3002  \u7ed3\u6784\u5f88\u7b80\u5355\uff0c\u53ea\u8981\u5b9e\u73b0Encoder\u4e0eDecoder\u518d\u5c06\u4ed6\u4eec\u4e32\u8d77\u6765\u5373\u53ef\u3002  \u8bba\u6587[2]\u4e2d\u7684Encoder\u4f7f\u7528\u7684\u662f\u4e00\u4e2a4\u5c42\u7684\u5355\u5411LSTM\uff0c\u8fd9\u4e00\u90e8\u5206\u4f7f\u7528RNN\u7684\u63a5\u53e3\u5373\u53ef\uff0c\u8fd8\u4e0d\u9700\u8981\u7528\u5230Seq2Seq\u4e2d\u7684\u63a5\u53e3\u3002\u7b2c\u4e00\u5f20\u56fe\u4e2d\u7684\u6a21\u578b\u6846\u67b6\u867d\u7136\u9610\u8ff0\u6e05\u695a\u4e86Encoder-Decoder\u8fd9\u79cd\u67b6\u6784\uff0c\u4f46\u662f\u5177\u4f53\u5b9e\u73b0\u4e0a\uff0c\u4e0d\u662f\u76f4\u63a5\u5c06\u5e8f\u5217['A', 'B', 'C', ' ']\u8f93\u5165\u5230Encoder\u4e2d\uff0cEncoder\u7684\u5b8c\u6574\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a  ---------------------Encoder----------------     \u56fe8:Encoder\u7ed3\u6784    input \uff1a\u4e0d\u662f\u539f\u59cb\u7684\u5e8f\u5217\uff0c\u800c\u662f\u5c06\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u8f6c\u6362\u4e3a\u5b57\u5178\u4e2d\u5bf9\u5e94\u7684id\u3002\u4e0d\u7ba1\u662ftrain\u8fd8\u662finference\u9636\u6bb5\uff0c\u4e3a\u4e86\u6548\u7387\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u4e2amini-batch\uff0c\u6240\u4ee5\u9700\u8981\u4e3ainput\u5b9a\u4e49\u4e00\u4e2aint\u578brank=2\u7684placeholder\u3002    embedding \uff1a\u5b9a\u4e49\u4e3atrainable=True\u7684\u53d8\u91cf\uff0c\u8fd9\u6837\u5373\u4f7f\u4f7f\u7528pre-trained\u7684\u8bcd\u5411\u91cf\u4e5f\u53ef\u4ee5\u5728\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u7a0b\u4e2d\u8c03\u4f18\u3002    MultiLayer_LSTM \uff1a\u63a5\u6536\u7684\u8f93\u5165\u662f\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\u3002    \u5176\u4e2d\uff0ctf.nn.dynamic_rnn\u65b9\u6cd5\u63a5\u6536encoder\u5b9e\u4f8b\u4ee5\u53caembbeded\u5411\u91cf\u4e4b\u540e\uff0c\u5c31\u4f1a\u8f93\u51fa\u5305\u542b\u6bcf\u4e2a\u65f6\u523bhidden state\u7684outputs\u4ee5\u53cafinal state\uff0c\u5982\u679c\u521d\u59cb\u72b6\u6001\u4e3a0\u7684\u8bdd\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u58f0\u660ezero_state\u518d\u5c06\u5176\u4f5c\u4e3a\u53c2\u6570\u4f20\u5165\uff0c\u53ea\u9700\u8981\u6307\u5b9astate\u7684dtype\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u4e2d\u4f1a\u5c06\u521d\u59cb\u72b6\u6001\u81ea\u52a8\u521d\u59cb\u5316\u4e3a0\u5411\u91cf  ------------------Decoder----------------------     \u56fe9:Encoder\u7ed3\u6784    input \uff1a\u4e0eencoder\u7684\u4e00\u6837\uff0c\u4e5f\u662f\u5e8f\u5217\u5143\u7d20\u5bf9\u5e94\u7684id\u3002    embedding \uff1a\u89c6\u60c5\u51b5\u800c\u5b9a\u9700\u4e0d\u9700\u8981\u4e0eencoder\u7684embedding\u4e0d\u540c\uff0c\u6bd4\u5982\u5728\u7ffb\u8bd1\u4e2d\uff0c\u6e90\u8bed\u8a00\u4e0e\u76ee\u6807\u8bed\u8a00\u7684\u8bcd\u5411\u91cf\u7a7a\u95f4\u5c31\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u50cf\u6587\u672c\u6458\u8981\u8fd9\u79cd\u90fd\u662f\u57fa\u4e8e\u4e00\u79cd\u8bed\u8a00\u7684\uff0cencoder\u4e0edecoder\u7684embedding matrix\u662f\u53ef\u4ee5\u5171\u7528\u7684\u3002    Dense_Layer \uff1a\u4e0eencoder\u4ec5\u8f93\u51fahidden state\u4e0d\u540c\uff0cdecoder\u9700\u8981\u8f93\u51fa\u6bcf\u4e2a\u65f6\u523b\u8bcd\u5178\u4e2d\u5404token\u7684\u6982\u7387\uff0c\u56e0\u6b64\u8fd8\u9700\u8981\u4e00\u4e2adense layer\u5c06hidden state\u5411\u91cf\u8f6c\u6362\u4e3a\u7ef4\u5ea6\u7b49\u4e8evocabulary_size\u7684\u5411\u91cf\uff0c\u7136\u540e\u518d\u5c06dense layer\u8f93\u51fa\u7684logits\u7ecf\u8fc7softmax\u5c42\u5f97\u5230\u6700\u7ec8\u7684token\u6982\u7387\u3002    Decoder \u7684\u5b9a\u4e49\u9700\u8981\u533a\u5206inference\u9636\u6bb5\u8fd8\u662ftrain\u9636\u6bb5\u3002    inference\u9636\u6bb5\uff0cdecoder\u7684\u8f93\u51fa\u662f\u672a\u77e5\u7684\uff0c\u5bf9\u4e8e\u751f\u6210['W', 'X', 'Y', 'Z', ' ']\u5e8f\u5217\uff0c\u662f\u5728decoder\u8f93\u51fatoken 'W'\u4e4b\u540e\uff0c\u518d\u5c06'W'\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ed3\u5408\u6b64\u65f6\u7684hidden state\uff0c\u63a8\u65ad\u51fa\u4e0b\u4e00\u4e2atoken 'X'\uff0c\u4ee5\u6b64\u7c7b\u63a8\u76f4\u5230\u8f93\u51fa\u4e3a \u6216\u8fbe\u5230\u6700\u957f\u5e8f\u5217\u957f\u5ea6\u4e4b\u540e\u7ec8\u6b62\u3002    \u800c\u5728train\u9636\u6bb5\uff0cdecoder\u5e94\u8be5\u8f93\u51fa\u7684\u5e8f\u5217\u662f\u5df2\u77e5\u7684\uff0c\u4e0d\u7ba1\u6700\u7ec8output\u7684\u7ed3\u679c\u662f\u4ec0\u4e48\uff0c\u90fd\u5c06\u5df2\u77e5\u5e8f\u5217\u4e2d\u7684token\u4f9d\u6b21\u8f93\u5165\u3002train\u7684\u9636\u6bb5\u5982\u679c\u4e5f\u5c06\u8f93\u51fa\u7684\u7ed3\u679c\u518d\u4f5c\u4e3a\u8f93\u5165\uff0c\u4e00\u65e6\u524d\u9762\u7684\u4e00\u6b65\u9519\u4e86\uff0c\u90fd\u4f1a\u653e\u5927\u8bef\u5dee\uff0c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u4e0d\u7a33\u5b9a\u3002    decoder\u5c06\u7528\u5230seq2seq\u4e2d\u7684TrainingHelper, GreedyEmbeddingHelper, BasicDecoder\u4e09\u4e2a\u7c7b\uff0c\u4ee5\u53cadynamic_decode\u65b9\u6cd5\uff0c\u8fd8\u5c06\u7528\u5230tensorflow.python.layers.core\u4e0b\u7684Dense\u7c7b\u3002    1.BasicDecoder  \u5b9e\u73b0decoder\u6700\u5148\u5173\u6ce8\u5230\u7684\u5c31\u662fBasicDecoder\uff0c\u5b83\u7684\u6784\u9020\u51fd\u6570\u4e0e\u53c2\u6570\u7684\u5b9a\u4e49\u5982\u4e0b\uff1a  \n__init__( cell, helper, initial_state, output_layer=None ) \n- cell: An RNNCell instance. \n- helper: A Helper instance. \n- initial_state: A (possibly nested tuple of\u2026) tensors and TensorArrays. The initial state of the RNNCell. \n- output_layer: (Optional) An instance of tf.layers.Layer, i.e., tf.layers.Dense. Optional layer to apply to the RNN output prior to storing the result or sampling.    cell \uff1a\u5728\u8fd9\u91cc\u5c31\u662f\u4e00\u4e2a\u591a\u5c42LSTM\u7684\u5b9e\u4f8b\uff0c\u4e0e\u5b9a\u4e49encoder\u65f6\u65e0\u5f02     helper \uff1a\u8fd9\u91cc\u53ea\u662f\u7b80\u5355\u8bf4\u660e\u662f\u4e00\u4e2aHelper\u5b9e\u4f8b\uff0c\u7b2c\u4e00\u6b21\u770b\u6587\u6863\u7684\u65f6\u5019\u80af\u5b9a\u8fd8\u4e0d\u77e5\u9053\u8fd9\u4e2aHelper\u662f\u4ec0\u4e48\uff0c\u4e0d\u7528\u7740\u6025\uff0c\u770b\u5230\u5177\u4f53\u7684Helper\u5b9e\u4f8b\u5c31\u660e\u767d\u4e86     initial_state \uff1aencoder\u7684final state\uff0c\u7c7b\u578b\u8981\u4e00\u81f4\uff0c\u4e5f\u5c31\u662f\u8bf4\u5982\u679cencoder\u7684final state\u662ftuple\u7c7b\u578b(\u5982LSTM\u7684\u5305\u542b\u4e86cell state\u4e0ehidden state)\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684\u8f93\u5165\u4e5f\u5fc5\u987b\u662ftuple\u3002\u76f4\u63a5\u5c06encoder\u7684final_state\u4f5c\u4e3a\u8fd9\u4e2a\u53c2\u6570\u8f93\u5165\u5373\u53ef     output_layer \uff1a\u5bf9\u5e94\u7684\u5c31\u662f\u6846\u67b6\u56fe\u4e2d\u7684Dense_Layer\uff0c\u53ea\u4e0d\u8fc7\u6587\u6863\u91cc\u5199tf.layers.Dense\uff0c\u4f46\u662ftf.layers\u4e0b\u53ea\u6709dense\u65b9\u6cd5\uff0cDense\u7684\u5b9e\u4f8b\u8fd8\u9700\u8981from tensorflow.python.layers.core import Dense\u3002    BasicDecoder\u7684\u4f5c\u7528\u5c31\u662f\u5b9a\u4e49\u4e00\u4e2a\u5c01\u88c5\u4e86decoder\u5e94\u8be5\u6709\u7684\u529f\u80fd\u7684\u5b9e\u4f8b\uff0c\u6839\u636eHelper\u5b9e\u4f8b\u7684\u4e0d\u540c\uff0c\u8fd9\u4e2adecoder\u53ef\u4ee5\u5b9e\u73b0\u4e0d\u540c\u7684\u529f\u80fd\uff0c\u6bd4\u5982\u5728train\u7684\u9636\u6bb5\uff0c\u4e0d\u628a\u8f93\u51fa\u91cd\u65b0\u4f5c\u4e3a\u8f93\u5165\uff0c\u800c\u5728inference\u9636\u6bb5\uff0c\u5c06\u8f93\u51fa\u63a5\u5230\u8f93\u5165\u3002  2.TrainingHelper  \u6784\u9020\u51fd\u6570\u4e0e\u53c2\u6570\u5982\u4e0b\uff1a  __init__( inputs, sequence_length, time_major=False, name=None ) \n- inputs: A (structure of) input tensors. \n- sequence_length: An int32 vector tensor. \n- time_major: Python bool. Whether the tensors in inputs are time major. If False (default), they are assumed to be batch major. \n- name: Name scope for any created operations.    inputs \uff1a\u5bf9\u5e94Decoder\u6846\u67b6\u56fe\u4e2d\u7684embedded_input\uff0ctime_major=False\u7684\u65f6\u5019\uff0cinputs\u7684shape\u5c31\u662f[batch_size, sequence_length, embedding_size] \uff0ctime_major=True\u65f6\uff0cinputs\u7684shape\u4e3a[sequence_length, batch_size, embedding_size]     sequence_length \uff1a\u8fd9\u4e2a\u6587\u6863\u5199\u7684\u592a\u7b80\u7565\u4e86\uff0c\u4e0d\u8fc7\u5728\u6e90\u7801\u4e2d\u53ef\u4ee5\u770b\u51fa\u6307\u7684\u662f\u5f53\u524dbatch\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u7684\u957f\u5ea6(self._batch_size = array_ops.size(sequence_length))\u3002     time_major \uff1a\u51b3\u5b9ainputs Tensor\u524d\u4e24\u4e2adim\u8868\u793a\u7684\u542b\u4e49 \nname\uff1a\u5982\u6587\u6863\u6240\u8ff0    TrainingHelper\u7528\u4e8etrain\u9636\u6bb5\uff0cnext_inputs\u65b9\u6cd5\u4e00\u6837\u4e5f\u63a5\u6536outputs\u4e0esample_ids\uff0c\u4f46\u662f\u53ea\u662f\u4ece\u521d\u59cb\u5316\u65f6\u7684inputs\u8fd4\u56de\u4e0b\u4e00\u65f6\u523b\u7684\u8f93\u5165\u3002  3.GreedyEmbeddingHelper  __init__( embedding, start_tokens, end_token ) \n- embedding: A callable that takes a vector tensor of ids (argmax ids), or the params argument for embedding_lookup. The returned tensor will be passed to the decoder input. \n- start_tokens: int32 vector shaped [batch_size], the start tokens. \n- end_token: int32 scalar, the token that marks end of decoding.\n\nA helper for use during inference. \nUses the argmax of the output (treated as logits) and passes the result through an embedding layer to get the next input.  \u5b98\u65b9\u6587\u6863\u5df2\u7ecf\u8bf4\u660e\uff0c\u8fd9\u662f\u7528\u4e8einference\u9636\u6bb5\u7684helper\uff0c\u5c06output\u8f93\u51fa\u540e\u7684logits\u4f7f\u7528argmax\u83b7\u5f97id\u518d\u7ecf\u8fc7embedding layer\u6765\u83b7\u53d6\u4e0b\u4e00\u65f6\u523b\u7684\u8f93\u5165\u3002   embedding \uff1aparams argument for embedding_lookup\uff0c\u4e5f\u5c31\u662f \u5b9a\u4e49\u7684embedding \u53d8\u91cf\u4f20\u5165\u5373\u53ef\u3002   start_tokens \uff1a batch\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u8d77\u59cb\u8f93\u5165\u7684token_id   end_token \uff1a\u5e8f\u5217\u7ec8\u6b62\u7684token_id   4.dynamic_decode  dynamic_decode( decoder, output_time_major=False, impute_finished=False, maximum_iterations=None, parallel_iterations=32, swap_memory=False, scope=None)  \u8fd9\u4e2a\u65b9\u6cd5\u5f88\u76f4\u89c2\uff0c\u5c06\u5b9a\u4e49\u597d\u7684decoder\u5b9e\u4f8b\u4f20\u5165\uff0c\u5176\u4ed6\u51e0\u4e2a\u53c2\u6570\u6587\u6863\u4ecb\u7ecd\u7684\u5f88\u6e05\u695a\u3002\u5f88\u503c\u5f97\u5b66\u4e60\u7684\u662f\u5176\u4e2d\u5982\u4f55\u4f7f\u7528control flow ops\u6765\u5b9e\u73b0dynamic\u7684\u8fc7\u7a0b\u3002  ------------------\u4ee3\u7801--------------------  \u7efc\u5408\u4f7f\u7528\u4e0a\u8ff0\u63a5\u53e3\u5b9e\u73b0\u57fa\u672cEncoder-Decoder\u6a21\u578b\u7684\u4ee3\u7801\u5982\u4e0b  import tensorflow as tf\nfrom tensorflow.contrib.seq2seq import *\nfrom tensorflow.python.layers.core import Dense\n\n\nclass Seq2SeqModel(object):\n\n    def __init__(self, rnn_size, layer_size, encoder_vocab_size, \n        decoder_vocab_size, embedding_dim, grad_clip, is_inference=False):\n        # define inputs\n        self.input_x = tf.placeholder(tf.int32, shape=[None, None], name='input_ids')\n\n        # define embedding layer\n        with tf.variable_scope('embedding'):\n            encoder_embedding = tf.Variable(tf.truncated_normal(shape=[encoder_vocab_size, embedding_dim], stddev=0.1), \n                name='encoder_embedding')\n            decoder_embedding = tf.Variable(tf.truncated_normal(shape=[decoder_vocab_size, embedding_dim], stddev=0.1),\n                name='decoder_embedding')\n\n        # define encoder\n        with tf.variable_scope('encoder'):\n            encoder = self._get_simple_lstm(rnn_size, layer_size)\n\n        with tf.device('/cpu:0'):\n            input_x_embedded = tf.nn.embedding_lookup(encoder_embedding, self.input_x)\n\n        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder, input_x_embedded, dtype=tf.float32)\n\n        # define helper for decoder\n        if is_inference:\n            self.start_tokens = tf.placeholder(tf.int32, shape=[None], name='start_tokens')\n            self.end_token = tf.placeholder(tf.int32, name='end_token')\n            helper = GreedyEmbeddingHelper(decoder_embedding, self.start_tokens, self.end_token)\n        else:\n            self.target_ids = tf.placeholder(tf.int32, shape=[None, None], name='target_ids')\n            self.decoder_seq_length = tf.placeholder(tf.int32, shape=[None], name='batch_seq_length')\n            with tf.device('/cpu:0'):\n                target_embeddeds = tf.nn.embedding_lookup(decoder_embedding, self.target_ids)\n            helper = TrainingHelper(target_embeddeds, self.decoder_seq_length)\n\n        with tf.variable_scope('decoder'):\n            fc_layer = Dense(decoder_vocab_size)\n            decoder_cell = self._get_simple_lstm(rnn_size, layer_size)\n            decoder = BasicDecoder(decoder_cell, helper, encoder_state, fc_layer)\n\n        logits, final_state, final_sequence_lengths = dynamic_decode(decoder)\n\n        if not is_inference:\n            targets = tf.reshape(self.target_ids, [-1])\n            logits_flat = tf.reshape(logits.rnn_output, [-1, decoder_vocab_size])\n            print ('shape logits_flat:{}'.format(logits_flat.shape))\n            print ('shape logits:{}'.format(logits.rnn_output.shape))\n\n            self.cost = tf.losses.sparse_softmax_cross_entropy(targets, logits_flat)\n\n            # define train op\n            tvars = tf.trainable_variables()\n            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), grad_clip)\n\n            optimizer = tf.train.AdamOptimizer(1e-3)\n            self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n        else:\n            self.prob = tf.nn.softmax(logits)\n\n    def _get_simple_lstm(self, rnn_size, layer_size):\n        lstm_layers = [tf.contrib.rnn.LSTMCell(rnn_size) for _ in xrange(layer_size)]\n        return tf.contrib.rnn.MultiRNNCell(lstm_layers)  ---------------\u5b9e\u4f8b----------------  \n\u968f\u673a\u5e8f\u5217\u751f\u6210\u5668\ndef random_sequences(length_from, length_to, vocab_lower, vocab_upper, batch_size):\n    def random_length():\n        if length_from == length_to:\n            return length_from\n        return np.random.randint(length_from, length_to + 1)\n\n    while True:\n        yield [\n            np.random.randint(low=vocab_lower, high=vocab_upper, size=random_length()).tolist()\n            for _ in range(batch_size)\n            ]  \u6784\u5efa\u4e00\u4e2a\u968f\u673a\u5e8f\u5217\u751f\u6210\u5668\u65b9\u4fbf\u540e\u9762\u751f\u6210\u5e8f\u5217\uff0c\u5176\u4e2d length_from \u548c length_to\u8868\u793a\u5e8f\u5217\u7684\u957f\u5ea6\u8303\u56f4\u4ece\u591a\u5c11\u5230\u591a\u5c11\uff0cvocab_lower \u548c vocab_upper \u8868\u793a\u751f\u6210\u7684\u5e8f\u5217\u503c\u7684\u8303\u56f4\u4ece\u591a\u5c11\u5230\u591a\u5c11\uff0cbatch_size \u5373\u662f\u6279\u7684\u6570\u91cf\u3002  \n\n\n\u586b\u5145\u5e8f\u5217\ndef make_batch(inputs, max_sequence_length=None):\n    sequence_lengths = [len(seq) for seq in inputs]\n    batch_size = len(inputs)\n    if max_sequence_length is None:\n        max_sequence_length = max(sequence_lengths)\n    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32)\n    for i, seq in enumerate(inputs):\n        for j, element in enumerate(seq):\n            inputs_batch_major[i, j] = element\n    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n    return inputs_time_major, sequence_lengths  \u751f\u6210\u7684\u968f\u673a\u5e8f\u5217\u7684\u957f\u5ea6\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u9700\u8981\u5bf9\u77ed\u7684\u5e8f\u5217\u7528\u6765\u586b\u5145\uff0c\u800c\u53ef\u8bbe\u4e3a0\uff0c\u53d6\u6700\u957f\u7684\u5e8f\u5217\u4f5c\u4e3a\u6bcf\u4e2a\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u4e0d\u8db3\u7684\u586b\u5145\uff0c\u7136\u540e\u518d\u8f6c\u6362\u6210time major\u5f62\u5f0f\u3002  \u6784\u5efa\u56fe\nencoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\necoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\ndecoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')  \u521b\u5efa\u4e09\u4e2a\u5360\u4f4d\u7b26\uff0c\u5206\u522b\u4e3aencoder\u7684\u8f93\u5165\u5360\u4f4d\u7b26\u3001decoder\u7684\u8f93\u5165\u5360\u4f4d\u7b26\u548cdecoder\u7684target\u5360\u4f4d\u7b26\u3002  embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\nencoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)  \u5c06encoder\u548cdecoder\u7684\u8f93\u5165\u505a\u4e00\u4e2a\u5d4c\u5165\u64cd\u4f5c\uff0c\u5bf9\u4e8e\u5927\u8bcd\u6c47\u91cf\u8fd9\u4e2a\u80fd\u8fbe\u5230\u964d\u7ef4\u7684\u6548\u679c\uff0c\u5d4c\u5165\u64cd\u4f5c\u4e5f\u662f\u5f88\u5e38\u7528\u7684\u65b9\u5f0f\u4e86\u3002\u5728seq2seq\u6a21\u578b\u4e2d\uff0cencoder\u548cdecoder\u90fd\u662f\u5171\u7528\u4e00\u4e2a\u5d4c\u5165\u5c42\u5373\u53ef\u3002\u5d4c\u5165\u5c42\u7684\u5411\u91cf\u5f62\u72b6\u4e3a[vocab_size, input_embedding_size]\uff0c\u521d\u59cb\u503c\u4ece-1\u52301\uff0c\u540e\u9762\u8bad\u7ec3\u4f1a\u81ea\u52a8\u8c03\u6574\u3002  encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\nencoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n        encoder_cell, encoder_inputs_embedded,\n        dtype=tf.float32, time_major=True,\n    )\ndecoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\ndecoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n        decoder_cell, decoder_inputs_embedded,\n        initial_state=encoder_final_state,\n        dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n    )  \u521b\u5efaencoder\u548cdecoder\u7684LSTM\u795e\u7ecf\u7f51\u7edc\uff0cencoder_hidden_units \u4e3aLSTM\u9690\u5c42\u6570\u91cf\uff0c\u8bbe\u5b9a\u8f93\u5165\u683c\u5f0f\u4e3atime major\u683c\u5f0f\u3002\u8fd9\u91cc\u6211\u4eec\u4e0d\u5173\u5fc3encoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u6211\u4eec\u8981\u7684\u662f\u5b83\u7684\u6700\u7ec8\u72b6\u6001encoder_final_state\uff0c\u5c06\u5176\u4f5c\u4e3adecoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u521d\u59cb\u72b6\u6001\u3002  decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\ndecoder_prediction = tf.argmax(decoder_logits, 2)\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n        logits=decoder_logits,\n    )\nloss = tf.reduce_mean(stepwise_cross_entropy)\ntrain_op = tf.train.AdamOptimizer().minimize(loss)  \u5bf9\u4e8edecoder\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u6211\u4eec\u8981\u4e00\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c\u6240\u4ee5\u9700\u8981\u4e00\u4e2a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff0c\u8f93\u51fa\u5c42\u795e\u7ecf\u5143\u6570\u91cf\u662f\u8bcd\u6c47\u7684\u6570\u91cf\u3002\u8f93\u51fa\u5c42\u6700\u5927\u503c\u5bf9\u5e94\u7684\u795e\u7ecf\u5143\u5373\u4e3a\u9884\u6d4b\u7684\u7c7b\u522b\u3002\u8f93\u51fa\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570\u7528softmax\uff0c\u635f\u5931\u51fd\u6570\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u3002  \u521b\u5efa\u4f1a\u8bdd\nwith tf.Session(graph=train_graph) as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(epochs):\n        batch = next(batches)\n        encoder_inputs_, _ = make_batch(batch)\n        decoder_targets_, _ = make_batch([(sequence) + [EOS] for sequence in batch])\n        decoder_inputs_, _ = make_batch([[EOS] + (sequence) for sequence in batch])\n        feed_dict = {encoder_inputs: encoder_inputs_, decoder_inputs: decoder_inputs_,\n                     decoder_targets: decoder_targets_,\n                     }\n        _, l = sess.run([train_op, loss], feed_dict)\n        loss_track.append(l)\n        if epoch == 0 or epoch % 1000 == 0:\n            print('loss: {}'.format(sess.run(loss, feed_dict)))\n            predict_ = sess.run(decoder_prediction, feed_dict)\n            for i, (inp, pred) in enumerate(zip(feed_dict[encoder_inputs].T, predict_.T)):\n                print('input > {}'.format(inp))\n                print('predicted > {}'.format(pred))\n                if i >= 20:\n                    break  \u521b\u5efa\u4f1a\u8bdd\u5f00\u59cb\u6267\u884c\uff0c\u6bcf\u6b21\u751f\u6210\u4e00\u6279\u6570\u91cf\uff0c\u7528 make_batch \u5206\u522b\u521b\u5efaencoder\u8f93\u5165\u3001decoder\u7684target\u548cdecoder\u7684\u8f93\u5165\u3002\u5176\u4e2dtarget\u9700\u8981\u5728\u540e\u9762\u52a0\u4e0a[EOS]\uff0c\u5b83\u8868\u793a\u53e5\u5b50\u7684\u7ed3\u5c3e\uff0c\u540c\u65f6\u8f93\u5165\u4e5f\u52a0\u4e0a[EOS]\u8868\u793a\u7f16\u7801\u5f00\u59cb\u3002\u6bcf\u8bad\u7ec31000\u8bcd\u8f93\u51fa\u770b\u770b\u6548\u679c\u3002  1.2 Attention Seq2Seq\u6a21\u578b  \u4e0b\u9762\u6211\u4eec\u68b3\u7406\u4e00\u4e0b\u5e26Attention\u7684seq2seq\u7684\u7ed3\u6784  -------------Bi-RNN Encoder-----------------------        ----------------Attention-Decoder------------------        \u8be6\u7ec6\u7684\u5206\u6790\u53ef\u4ee5\u53c2\u89c1\u53c2\u8003\u6587\u732e\u30108\u3011\u3002  1.3 tf-seq2seq\u5f00\u6e90\u6846\u67b6  2017\u5e744\u670811\u65e5\uff0cGoogle\u7684\u5927\u8111\u7814\u7a76\u56e2\u961f\u53d1\u5e03\u4e86 tf-seq2seq\u8fd9\u4e2a\u5f00\u6e90\u7684TensorFlow\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u8f7b\u6613\u8fdb\u884c\u5b9e\u9a8c\u800c\u8fbe\u5230\u73b0\u6709\u7684\u6548\u679c\uff0c\u56e2\u961f\u5236\u4f5c\u4e86\u8be5\u6846\u67b6\u7684\u4ee3\u7801\u5e93\u548c\u6a21\u5757\u7b49\uff0c\u80fd\u591f\u6700\u597d\u5730\u652f\u6301\u5176\u529f\u80fd\u3002\u53bb\u5e74\uff0c\u8be5\u56e2\u961f\u53d1\u5e03\u4e86Google\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\uff08GoogleNeural Machine Translation\uff0cGNMT\uff09\uff0c\u5b83\u662f\u4e00\u4e2a\u5e8f\u5217\u5230\u5e8f\u5217sequence-to-sequence\uff08\u201cseq2seq\u201d\uff09\u7684\u6a21\u578b\uff0c\u76ee\u524d\u7528\u4e8eGoogle\u7ffb\u8bd1\u7cfb\u7edf\u4e2d\u3002\u867d\u7136GNMT\u5728\u7ffb\u8bd1\u8d28\u91cf\u4e0a\u6709\u957f\u8db3\u7684\u8fdb\u6b65\uff0c\u4f46\u662f\u5b83\u8fd8\u662f\u53d7\u9650\u4e8e\u8bad\u7ec3\u7684\u6846\u67b6\u65e0\u6cd5\u5bf9\u5916\u90e8\u7814\u7a76\u4eba\u5458\u5f00\u653e\u7684\u77ed\u677f\u3002  2.keras\u5b9e\u73b0seq2seq  \u5728\u5b98\u65b9\u7684keras\u5b9e\u4f8b\u4e2d\u6709\u5b8c\u6574\u7684seq2seq,\u53ef\u4ee5\u53c2\u8003\u53c2\u8003\u6587\u732e\u30109\u3011\u3002  3.\u53c2\u8003\u6587\u732e  [1]  https://google.github.io/seq2seq/  [2]  https://github.com/DataXujing/seq2seq  [3]  https://www.w3cschool.cn/tensorflow_python/tensorflow_python-i8jh28vt.html  [4]  http://www.tensorfly.cn/  [5]  http://blog.csdn.net/thriving_fcl/article/details/74165062  [6]  http://blog.csdn.net/wangyangzhizhou/article/details/77977655  [7]  https://www.bilibili.com/video/av12005043/  [8]  http://blog.csdn.net/thriving_fcl/article/details/74853556  [9]  https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py",
            "title": "seq2seq\u6a21\u578bPython\u5b9e\u73b0"
        },
        {
            "location": "/chapter4/",
            "text": "\u5b9e\u73b0\u6587\u672cQA\u8f6f\u4ef6\n\n\n\n\n\n\n\u82b1\u4e86\u4e00\u5929\u65f6\u95f4\uff0c\u505a\u4e86\u4e2a\u804a\u5929\u673a\u5668\u4eba\n\n\n\u672c\u6765\u6253\u7b97\u7528seq2seq\u4f5c\u4e3amodel\u53bb\u8bad\u7ec3\uff08\u8bad\u7ec3\u65f6\u95f4\u8fd8\u633a\u957fGPU or TPU not CPU\uff0c\u7f51\u4e0a\u6ca1\u6709\u8bad\u7ec3\u597d\u4fdd\u5b58\u4e0b\u6765\u7684\u6a21\u578b\uff09\n\n\n\u65f6\u95f4\u6bd4\u8f83\u7d27\u5f20\uff0c\u4e3a\u4e86\u5feb\u901f\u5b9e\u73b0\u8c03\u7528\u4e86\u56fe\u7075\u673a\u5668\u4eba\u7684API(\u4e91\u670d\u52a1)\nhttp://www.tuling123.com/\n\n\n\u7ed9\u6211\u70b9\u65f6\u95f4\uff0c\u8ba9\u6211\u7684seq2seq\u8bad\u7ec3\u51fa\u6765\uff0c\u76f4\u63a5\u4e0a\u9635\n\n\n\n\n\u8be5\u804a\u5929\u5de5\u5177\u7684\u538b\u7f29\u5305\u5df2\u4e0a\u4f20\n\n\n\u94fe\u63a5\uff1a\nhttps://pan.baidu.com/s/1hupgqP2\n \u5bc6\u7801\uff1a152u",
            "title": "\u5b9e\u73b0\u6587\u672cQA\u8f6f\u4ef6"
        },
        {
            "location": "/chapter4/#qa",
            "text": "\u82b1\u4e86\u4e00\u5929\u65f6\u95f4\uff0c\u505a\u4e86\u4e2a\u804a\u5929\u673a\u5668\u4eba  \u672c\u6765\u6253\u7b97\u7528seq2seq\u4f5c\u4e3amodel\u53bb\u8bad\u7ec3\uff08\u8bad\u7ec3\u65f6\u95f4\u8fd8\u633a\u957fGPU or TPU not CPU\uff0c\u7f51\u4e0a\u6ca1\u6709\u8bad\u7ec3\u597d\u4fdd\u5b58\u4e0b\u6765\u7684\u6a21\u578b\uff09  \u65f6\u95f4\u6bd4\u8f83\u7d27\u5f20\uff0c\u4e3a\u4e86\u5feb\u901f\u5b9e\u73b0\u8c03\u7528\u4e86\u56fe\u7075\u673a\u5668\u4eba\u7684API(\u4e91\u670d\u52a1) http://www.tuling123.com/  \u7ed9\u6211\u70b9\u65f6\u95f4\uff0c\u8ba9\u6211\u7684seq2seq\u8bad\u7ec3\u51fa\u6765\uff0c\u76f4\u63a5\u4e0a\u9635   \u8be5\u804a\u5929\u5de5\u5177\u7684\u538b\u7f29\u5305\u5df2\u4e0a\u4f20  \u94fe\u63a5\uff1a https://pan.baidu.com/s/1hupgqP2  \u5bc6\u7801\uff1a152u",
            "title": "\u5b9e\u73b0\u6587\u672cQA\u8f6f\u4ef6"
        },
        {
            "location": "/chapter5/",
            "text": "\u5b9e\u73b0(\u8054\u4fe1)QA\u7cfb\u7edf\u7684\u53ef\u884c\u6027\n\n\n\u4e0d\u4f46 \u53ef\u884c \u800c\u4e14 \u53ef\u884c\uff01\n\n\n\n1.\u5982\u4f55\u6539\u8fdb\u6587\u672cQA\u8f6f\u4ef6\n\n\n\u5982\u679c\u60f3\u66f4\u8d34\u8fd1\u4e8e\u4e1a\u52a1\u573a\u666f\uff08\u6bd4\u5982\u67d0\u4e1a\u52a1\u9886\u57df\u77e5\u8bc6\u7684\u67e5\u8be2\uff0c\u77e5\u8bc6\u95ee\u7b54\uff0c\u767e\u5ea6\u641c\u7d22\uff0c\u667a\u80fd\u533b\u751f\uff0c\u50ac\u6536\uff09\uff0c\u6211\u4eec\u8981\u505a\u7684\u5c31\u662f\u4fee\u6539\u8bad\u7ec3\u96c6\uff0c\u4f7f\u5f97\u5e95\u5c42\u8c03\u7528\u7684\u6a21\u578b\u5b66\u4e60\u5230\u8be5\u4e1a\u52a1\u573a\u666f\u5c31\u597d\u4e86\uff0c\u8fd8\u6709\u53ef\u80fd\u9700\u8981\u8c03\u6574\u6a21\u578b\u7ed3\u6784\u6216\u53c2\u6570\u3002\n\n\n2.\u57fa\u4e8e\u6587\u672cQA\u8f6f\u4ef6\uff0c\u5982\u4f55\u5b9e\u73b0\u8bed\u97f3QA\n\n\n\u6211\u67e5\u4e86\u76f8\u5173\u8d44\u6599\uff0c\u56e2\u961f\u5b8c\u6210\u8bed\u97f3\u8bc6\u522b\u548c\u8bed\u97f3\u5408\u6210\u662f\u6709\u96be\u5ea6\u7684\uff0c\u8bed\u97f3\u8bc6\u522b\u8fd8\u53ef\u4ee5\uff0c\u4f46\u662f\u8bed\u97f3\u5408\u6210\u76ee\u524d\u57fa\u672c\u4e0d\u53ef\u80fd\u5b8c\u6210\u3002 \u6211\u4eec\u8981\u611f\u8c22\u4e00\u4e9b\u725bB\u7684\uff0c\u6709\u903c\u683c\u7684\u4e92\u8054\u7f51\u5927\u516c\u53f8\uff0c\u8ba9\u6211\u4eec\u505a\u6210QA\u7cfb\u7edf\u6210\u4e3a\u53ef\u80fd\u3002 \n\n\n\u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u8bed\u97f3\u8bc6\u522b\n\n\n\n\n\u5c06\u4eba\u7c7b\u8bed\u8a00\u8f6c\u5316\u4e3a\u6587\u672c\u7684\u6280\u672f\n\n\n\u667a\u80fd\u673a\u5668\u4eba\u7684\u5fc5\u5907\u6280\u80fd\n\n\n\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u5e94\u7528\n\n\n\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\uff1asphinx\uff0cwindows\n\n\n\u4e91\u8bed\u97f3\u8bc6\u522b\uff1a\u767e\u5ea6\uff0c\u79d1\u5927\u8baf\u98de\uff0c\u82f9\u679c\uff0c\u8c37\u6b4c(\u5899\u5916)\n\n\n\u5728\u7ebf\u8bed\u97f3\u8bc6\u522b\u7684\u7cbe\u5ea6\u8fdc\u9ad8\u4e8e\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\n\n\n\u767e\u5ea6\uff0c\u8baf\u98de\u7b49\u63d0\u4f9b\u7684\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\uff0c\u5b9e\u9645\u4e0a\u8fd8\u662f\u9700\u8981\u7f51\u7edc\uff0c\u9700\u8981\u4e0e\u4e91\u670d\u52a1\u5668\u901a\u8baf\u7684\n\n\n\n\n\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\n\n\n\n\n\u674e\u5f00\u590d\uff0csphinx\n\n\n\u5fae\u8f6f\uff0cwin7\u7cfb\u7edf\u5185\u7f6e\u7684\u8bed\u97f3\u8bc6\u522b\u5f15\u64ce\uff0c\u8bc6\u522b\u7387\u4f4e\uff0c\u7ecf\u8fc7\u91cd\u590d\u8bad\u7ec3\u540e\u53ef\u63d0\u9ad8\n\n\n\n\n\u5728\u7ebf\u8bed\u97f3\u8bc6\u522b\n\n\n\n\n\n\n\u79d1\u5927\u8baf\u98de\n\n\n\n\n\n\n\u8bc6\u522b\u7387\u9ad8\uff0c\u652f\u6301\u65b9\u8a00\uff08\u8d85\u8d5e\uff09\n\n\n\n\n\n\n\u6bcf\u5929500\u6b21\u514d\u8d39\u8c03\u7528\uff0c\u8d85\u8fc7\u90e8\u5206\u6536\u8d39\n\n\n\n\n\n\n\n\n\n\n\u767e\u5ea6\u8bed\u97f3\n\n\n\n\n\u8bc6\u522b\u7387\u9ad8\uff0c\u4e0d\u652f\u6301\u65b9\u8a00(\u652f\u6301\u7ca4\u8bed\uff09\n\n\n\u514d\u8d39\uff0c\u65e0\u9650\u6b21\u8c03\u7528\uff08\u4e1a\u754c\u826f\u5fc3\uff09\n\n\n\u6211\u5df2\u7ecf\u6d4b\u8bd5\uff0c\u8c03\u7528\u767e\u5ea6\u4e91\u8bed\u97f3\u7684\u670d\u52a1\uff0c\u5b8c\u6210\u521d\u6b65\u7684QA\u7cfb\u7edf\n\n\n\n\n\n\n\n\n\u82f9\u679c\n\n\n\n\n\u56e0\u5176\u72ec\u7acb\u7684\u786c\u4ef6\u548c\u8f6f\u4ef6\u7cfb\u7edf\n\n\n\u4f60\u4eec\u4f11\u60f3\u77e5\u9053\u6211\u662f\u600e\u4e48\u505a\u5230\u7684\n\n\n\n\n\n\n\n\n\u8c37\u6b4c\n\n\n\n\n\u514d\u8d39\uff0c\u4f46\u662f\u4f60\u627e\u4e0d\u5230\u6211\n\n\n\n\n\n\n\n\n\u767e\u5ea6\u4e91\u8bed\u97f3\n\n\n\n\n\u8bed\u97f3\u8bc6\u522b\uff0c\u8bed\u97f3\u5408\u6210\n\n\n\u514d\u8d39\u4f7f\u7528\n\n\n\u53ef\u7533\u8bf7\u65e0\u9650\u6b21\u8c03\u7528API\n\n\n\u63d0\u4f9b\u79fb\u52a8\u5e73\u53f0\u7684SDK\u63a5\u5165\uff0c\u5bf9\u4e8ePC\u5e73\u53f0\uff0c\u53ef\u4f7f\u7528REST API\u8bbf\u95ee\n\n\n\u63d0\u4f9bjava\uff0cC++\u7684\u8bbf\u95eedemo(\u597d\u50cf\u73b0\u5728\u4e5f\u6709Python\u7684\u8bbf\u95eeDemo\uff09\n\n\n\n\n\u4f7f\u7528\u6bd4\u8f83\u7b80\u5355\uff1a\n\n\n\n\n\u4e91\u7aef\u7a0b\u5e8f\u5f00\u53d1\n\n\n\u6ce8\u518c\u767e\u5ea6\u5f00\u53d1\u8005\n\n\n\u5efa\u7acb\u5e94\u7528\n\n\n\u63d0\u5347\u5e94\u7528\u6743\u9650\n\n\n\u8bb0\u4f4ftoken\u548ckey\n\n\nhttp://yuyin.baidu.com/\n\n\n\n\n\n\n\u5bf9\u4e8e\u8bed\u97f3\u5408\u6210\uff0c\u6211\u60f3\u6211\u4eec\u8fd8\u662f\u653e\u5f03\u5427\uff0c\u76f4\u63a5\u62ff\u7b2c\u4e09\u65b9\u7684\u5f00\u6e90\u4e91\u670d\u52a1\u63a5\u53e3\u5c31\u591f\u6211\u4eec\u7528\u4e86\uff0c\u4f60\u53ea\u8981\u63d0\u4f9b\u6b63\u786e\u7684\u6587\u672c\uff0c\u767e\u5ea6\u4e91\u8bed\u97f3\u5c31\u53ef\u4ee5\u53d8\u6362\u5404\u79cd\u58f0\u7ebf\u7684\u7ed9\u4f60\u63d0\u4f9b\u51c6\u786e\u7684\u8bed\u97f3\u5408\u6210\u3002\n\n\n\n\n\u57fa\u4e8e\u767e\u5ea6\u8bed\u8a00\u8bc6\u522b\u53ca\u5408\u6210\uff0c\u6211\u4eec\u5c31\u975e\u5e38\u5bb9\u6613\u4fee\u6539\u6211\u4eec\u7684\u5c0f\u8f6f\u4ef6\uff0c\u505a\u6210\u8bed\u97f3QA\u7cfb\u7edf\uff0c\u8fd9\u91cc\u8fb9\u9700\u8981\u7279\u522b\u7684\u95ee\u9898\u6709\uff1a\u591a\u7ebf\u7a0b\u5e76\u53d1\u8bc6\u522b\u5408\u6210\uff0c\u65ad\u70b9\u8bc6\u522b\uff0c\u8bed\u97f3\u964d\u566a\uff0c\u4e91\u670d\u52a1\u8c03\u7528\u3002\n\n\n\n\n\u96be\u70b9\uff1a \u8bed\u97f3\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u57fa\u4e8e\u4e1a\u52a1\u573a\u666f\u7684\u6587\u672cQA\u7cfb\u7edf\u7684\u8bad\u7ec3\uff0c\u4e0d\u8bba\u600e\u4e48\u6837\uff0c\u5148\u505a\u51fa\u6765\uff0c\u6162\u6162\u8c03\u6574\u3002\n\n\n\u8fd8\u6709\u6700\u91cd\u8981\u7684\u4e00\u70b9\u662f\uff0c\u804a\u5929\u673a\u5668\u4eba\u7684\u524d\u540e\u6587\u903b\u8f91\u6027\u57fa\u672c\u662f0\uff0c\u5979\u53ea\u4f1a\u5f88\u597d\u7684\u56de\u7b54\u4f60\u5f53\u524d\u7684\u95ee\u9898\n\n\n\nexample:\n\nA: \u4f60\u7238\u7238\u662f\u8c01\uff1f\n\u673a\u5668\u4eba\uff1a \u6211\u7238\u7238\u662fXXX\nA: \u6211\u521a\u624d\u95ee\u4f60\u7238\u7238\u662f\u8c01\u4e86\u6ca1\u6709\uff1f\n\u673a\u5668\u4eba\uff1a\u4ed6\u4e0d\u4f1a\u7ed3\u5408\u4e0a\u4e0b\u6587\u804a\u5929\u8bed\u5883\u6765\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ed6\u7684\u8bed\u8a00\u903b\u8f91\u63a8\u7406\u80fd\u529b\u57fa\u672c\u4e3a0",
            "title": "\u5b9e\u73b0(\u8054\u4fe1)QA\u7cfb\u7edf\u7684\u53ef\u884c\u6027"
        },
        {
            "location": "/chapter5/#qa",
            "text": "\u4e0d\u4f46 \u53ef\u884c \u800c\u4e14 \u53ef\u884c\uff01  1.\u5982\u4f55\u6539\u8fdb\u6587\u672cQA\u8f6f\u4ef6  \u5982\u679c\u60f3\u66f4\u8d34\u8fd1\u4e8e\u4e1a\u52a1\u573a\u666f\uff08\u6bd4\u5982\u67d0\u4e1a\u52a1\u9886\u57df\u77e5\u8bc6\u7684\u67e5\u8be2\uff0c\u77e5\u8bc6\u95ee\u7b54\uff0c\u767e\u5ea6\u641c\u7d22\uff0c\u667a\u80fd\u533b\u751f\uff0c\u50ac\u6536\uff09\uff0c\u6211\u4eec\u8981\u505a\u7684\u5c31\u662f\u4fee\u6539\u8bad\u7ec3\u96c6\uff0c\u4f7f\u5f97\u5e95\u5c42\u8c03\u7528\u7684\u6a21\u578b\u5b66\u4e60\u5230\u8be5\u4e1a\u52a1\u573a\u666f\u5c31\u597d\u4e86\uff0c\u8fd8\u6709\u53ef\u80fd\u9700\u8981\u8c03\u6574\u6a21\u578b\u7ed3\u6784\u6216\u53c2\u6570\u3002  2.\u57fa\u4e8e\u6587\u672cQA\u8f6f\u4ef6\uff0c\u5982\u4f55\u5b9e\u73b0\u8bed\u97f3QA  \u6211\u67e5\u4e86\u76f8\u5173\u8d44\u6599\uff0c\u56e2\u961f\u5b8c\u6210\u8bed\u97f3\u8bc6\u522b\u548c\u8bed\u97f3\u5408\u6210\u662f\u6709\u96be\u5ea6\u7684\uff0c\u8bed\u97f3\u8bc6\u522b\u8fd8\u53ef\u4ee5\uff0c\u4f46\u662f\u8bed\u97f3\u5408\u6210\u76ee\u524d\u57fa\u672c\u4e0d\u53ef\u80fd\u5b8c\u6210\u3002 \u6211\u4eec\u8981\u611f\u8c22\u4e00\u4e9b\u725bB\u7684\uff0c\u6709\u903c\u683c\u7684\u4e92\u8054\u7f51\u5927\u516c\u53f8\uff0c\u8ba9\u6211\u4eec\u505a\u6210QA\u7cfb\u7edf\u6210\u4e3a\u53ef\u80fd\u3002   \u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u8bed\u97f3\u8bc6\u522b   \u5c06\u4eba\u7c7b\u8bed\u8a00\u8f6c\u5316\u4e3a\u6587\u672c\u7684\u6280\u672f  \u667a\u80fd\u673a\u5668\u4eba\u7684\u5fc5\u5907\u6280\u80fd  \u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u5e94\u7528  \u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\uff1asphinx\uff0cwindows  \u4e91\u8bed\u97f3\u8bc6\u522b\uff1a\u767e\u5ea6\uff0c\u79d1\u5927\u8baf\u98de\uff0c\u82f9\u679c\uff0c\u8c37\u6b4c(\u5899\u5916)  \u5728\u7ebf\u8bed\u97f3\u8bc6\u522b\u7684\u7cbe\u5ea6\u8fdc\u9ad8\u4e8e\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b  \u767e\u5ea6\uff0c\u8baf\u98de\u7b49\u63d0\u4f9b\u7684\u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b\uff0c\u5b9e\u9645\u4e0a\u8fd8\u662f\u9700\u8981\u7f51\u7edc\uff0c\u9700\u8981\u4e0e\u4e91\u670d\u52a1\u5668\u901a\u8baf\u7684   \u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b   \u674e\u5f00\u590d\uff0csphinx  \u5fae\u8f6f\uff0cwin7\u7cfb\u7edf\u5185\u7f6e\u7684\u8bed\u97f3\u8bc6\u522b\u5f15\u64ce\uff0c\u8bc6\u522b\u7387\u4f4e\uff0c\u7ecf\u8fc7\u91cd\u590d\u8bad\u7ec3\u540e\u53ef\u63d0\u9ad8   \u5728\u7ebf\u8bed\u97f3\u8bc6\u522b    \u79d1\u5927\u8baf\u98de    \u8bc6\u522b\u7387\u9ad8\uff0c\u652f\u6301\u65b9\u8a00\uff08\u8d85\u8d5e\uff09    \u6bcf\u5929500\u6b21\u514d\u8d39\u8c03\u7528\uff0c\u8d85\u8fc7\u90e8\u5206\u6536\u8d39      \u767e\u5ea6\u8bed\u97f3   \u8bc6\u522b\u7387\u9ad8\uff0c\u4e0d\u652f\u6301\u65b9\u8a00(\u652f\u6301\u7ca4\u8bed\uff09  \u514d\u8d39\uff0c\u65e0\u9650\u6b21\u8c03\u7528\uff08\u4e1a\u754c\u826f\u5fc3\uff09  \u6211\u5df2\u7ecf\u6d4b\u8bd5\uff0c\u8c03\u7528\u767e\u5ea6\u4e91\u8bed\u97f3\u7684\u670d\u52a1\uff0c\u5b8c\u6210\u521d\u6b65\u7684QA\u7cfb\u7edf     \u82f9\u679c   \u56e0\u5176\u72ec\u7acb\u7684\u786c\u4ef6\u548c\u8f6f\u4ef6\u7cfb\u7edf  \u4f60\u4eec\u4f11\u60f3\u77e5\u9053\u6211\u662f\u600e\u4e48\u505a\u5230\u7684     \u8c37\u6b4c   \u514d\u8d39\uff0c\u4f46\u662f\u4f60\u627e\u4e0d\u5230\u6211     \u767e\u5ea6\u4e91\u8bed\u97f3   \u8bed\u97f3\u8bc6\u522b\uff0c\u8bed\u97f3\u5408\u6210  \u514d\u8d39\u4f7f\u7528  \u53ef\u7533\u8bf7\u65e0\u9650\u6b21\u8c03\u7528API  \u63d0\u4f9b\u79fb\u52a8\u5e73\u53f0\u7684SDK\u63a5\u5165\uff0c\u5bf9\u4e8ePC\u5e73\u53f0\uff0c\u53ef\u4f7f\u7528REST API\u8bbf\u95ee  \u63d0\u4f9bjava\uff0cC++\u7684\u8bbf\u95eedemo(\u597d\u50cf\u73b0\u5728\u4e5f\u6709Python\u7684\u8bbf\u95eeDemo\uff09   \u4f7f\u7528\u6bd4\u8f83\u7b80\u5355\uff1a   \u4e91\u7aef\u7a0b\u5e8f\u5f00\u53d1  \u6ce8\u518c\u767e\u5ea6\u5f00\u53d1\u8005  \u5efa\u7acb\u5e94\u7528  \u63d0\u5347\u5e94\u7528\u6743\u9650  \u8bb0\u4f4ftoken\u548ckey  http://yuyin.baidu.com/    \u5bf9\u4e8e\u8bed\u97f3\u5408\u6210\uff0c\u6211\u60f3\u6211\u4eec\u8fd8\u662f\u653e\u5f03\u5427\uff0c\u76f4\u63a5\u62ff\u7b2c\u4e09\u65b9\u7684\u5f00\u6e90\u4e91\u670d\u52a1\u63a5\u53e3\u5c31\u591f\u6211\u4eec\u7528\u4e86\uff0c\u4f60\u53ea\u8981\u63d0\u4f9b\u6b63\u786e\u7684\u6587\u672c\uff0c\u767e\u5ea6\u4e91\u8bed\u97f3\u5c31\u53ef\u4ee5\u53d8\u6362\u5404\u79cd\u58f0\u7ebf\u7684\u7ed9\u4f60\u63d0\u4f9b\u51c6\u786e\u7684\u8bed\u97f3\u5408\u6210\u3002   \u57fa\u4e8e\u767e\u5ea6\u8bed\u8a00\u8bc6\u522b\u53ca\u5408\u6210\uff0c\u6211\u4eec\u5c31\u975e\u5e38\u5bb9\u6613\u4fee\u6539\u6211\u4eec\u7684\u5c0f\u8f6f\u4ef6\uff0c\u505a\u6210\u8bed\u97f3QA\u7cfb\u7edf\uff0c\u8fd9\u91cc\u8fb9\u9700\u8981\u7279\u522b\u7684\u95ee\u9898\u6709\uff1a\u591a\u7ebf\u7a0b\u5e76\u53d1\u8bc6\u522b\u5408\u6210\uff0c\u65ad\u70b9\u8bc6\u522b\uff0c\u8bed\u97f3\u964d\u566a\uff0c\u4e91\u670d\u52a1\u8c03\u7528\u3002   \u96be\u70b9\uff1a \u8bed\u97f3\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u57fa\u4e8e\u4e1a\u52a1\u573a\u666f\u7684\u6587\u672cQA\u7cfb\u7edf\u7684\u8bad\u7ec3\uff0c\u4e0d\u8bba\u600e\u4e48\u6837\uff0c\u5148\u505a\u51fa\u6765\uff0c\u6162\u6162\u8c03\u6574\u3002  \u8fd8\u6709\u6700\u91cd\u8981\u7684\u4e00\u70b9\u662f\uff0c\u804a\u5929\u673a\u5668\u4eba\u7684\u524d\u540e\u6587\u903b\u8f91\u6027\u57fa\u672c\u662f0\uff0c\u5979\u53ea\u4f1a\u5f88\u597d\u7684\u56de\u7b54\u4f60\u5f53\u524d\u7684\u95ee\u9898  \nexample:\n\nA: \u4f60\u7238\u7238\u662f\u8c01\uff1f\n\u673a\u5668\u4eba\uff1a \u6211\u7238\u7238\u662fXXX\nA: \u6211\u521a\u624d\u95ee\u4f60\u7238\u7238\u662f\u8c01\u4e86\u6ca1\u6709\uff1f\n\u673a\u5668\u4eba\uff1a\u4ed6\u4e0d\u4f1a\u7ed3\u5408\u4e0a\u4e0b\u6587\u804a\u5929\u8bed\u5883\u6765\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ed6\u7684\u8bed\u8a00\u903b\u8f91\u63a8\u7406\u80fd\u529b\u57fa\u672c\u4e3a0",
            "title": "\u5b9e\u73b0(\u8054\u4fe1)QA\u7cfb\u7edf\u7684\u53ef\u884c\u6027"
        },
        {
            "location": "/about/",
            "text": "\u5728\u54ea\u53ef\u4ee5\u627e\u5230\u6211\n\n\n\n\n\u5173\u4e8ePython, R\uff0c\u7684\u9ad8\u7ea7\u7f16\u7a0b\u53ca\u673a\u5668\u5b66\u4e60\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u5b66\u4e60\u5fc3\u5f97\u53ef\u5728\u6211\u7684\u4e2a\u4eba\u4e3b\u9875:https://dataxujing.github.io/\uff0chttps://dataxujing.coding.me/(\u5e1d\u56fd\u56fd\u5185\u5efa\u8bae\u767b\u5f55\u8be5URL)\n\n\n\n\n\n\n\n\n\u6211\u5e73\u65f6\u6d3b\u8dc3\u5728 GitHub: https://github.com/DataXujing/(\u6211\u5927\u90e8\u5206\u7684R\u5305\u53caPython\u6a21\u5757\u4f1a\u6258\u7ba1\u5728Github\uff0c\u76f8\u5173\u95ee\u9898Github\u4e0a\u6709\u5927\u725b\u53ef\u4ee5\u4ea4\u6d41)\n\n\n\n\n\n\n\n\n\u6211\u8fd8\u4f1a\u5728Pypi\u4e0a\u6d3b\u8dc3\uff0c\u6211\u7684Python\u5305\u548c\u6a21\u5757\u4f1a\u6709\u4e00\u4efd\u5728Pypi\u4e0a\uff0c\u53ef\u4ee5\u901a\u8fc7pip install pkgname\u4e0b\u8f7d\u4f7f\u7528\n\n\n\n\n\n\n\n\n\u672c\u8282\u6559\u7a0b\u5df2\u5f00\u6e90\u5728\u7f51\u7edc\uff1ahttps://dataxujing.github.io/seq2seqlearn/\n\n\n\n\n\n\n\n\n\u5c0f\u7f16\u6c34\u5e73\u6709\u9650\uff0c\u5bf9NLP\u7406\u89e3\u4e5f\u4e0d\u662f\u5f88\u6df1\u5165\uff0c\u6587\u6863\u4e2d\u6709\u9519\u8bef\u6216\u4e0d\u5f53\u7684\u5730\u65b9\uff0c\u8bf7\u79fb\u6b65\u5230\n\u6211\u7684NLP\u9879\u76ee\n\u8fdb\u884c\u7559\u8a00\u6307\u6b63\uff0c\u5c0f\u7f16\u5728\u6b64\u4e00\u5e76\u8c22\u8fc7\u3002\n\n\n\n\n\n\n\n\n\u540e\u671f\u4f1a\u6301\u7eed\u66f4\u65b0\u3002\u3002\u3002\u3002\u3002\u3002",
            "title": "\u5173\u4e8e"
        },
        {
            "location": "/about/#_1",
            "text": "\u5173\u4e8ePython, R\uff0c\u7684\u9ad8\u7ea7\u7f16\u7a0b\u53ca\u673a\u5668\u5b66\u4e60\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u5b66\u4e60\u5fc3\u5f97\u53ef\u5728\u6211\u7684\u4e2a\u4eba\u4e3b\u9875:https://dataxujing.github.io/\uff0chttps://dataxujing.coding.me/(\u5e1d\u56fd\u56fd\u5185\u5efa\u8bae\u767b\u5f55\u8be5URL)     \u6211\u5e73\u65f6\u6d3b\u8dc3\u5728 GitHub: https://github.com/DataXujing/(\u6211\u5927\u90e8\u5206\u7684R\u5305\u53caPython\u6a21\u5757\u4f1a\u6258\u7ba1\u5728Github\uff0c\u76f8\u5173\u95ee\u9898Github\u4e0a\u6709\u5927\u725b\u53ef\u4ee5\u4ea4\u6d41)     \u6211\u8fd8\u4f1a\u5728Pypi\u4e0a\u6d3b\u8dc3\uff0c\u6211\u7684Python\u5305\u548c\u6a21\u5757\u4f1a\u6709\u4e00\u4efd\u5728Pypi\u4e0a\uff0c\u53ef\u4ee5\u901a\u8fc7pip install pkgname\u4e0b\u8f7d\u4f7f\u7528     \u672c\u8282\u6559\u7a0b\u5df2\u5f00\u6e90\u5728\u7f51\u7edc\uff1ahttps://dataxujing.github.io/seq2seqlearn/     \u5c0f\u7f16\u6c34\u5e73\u6709\u9650\uff0c\u5bf9NLP\u7406\u89e3\u4e5f\u4e0d\u662f\u5f88\u6df1\u5165\uff0c\u6587\u6863\u4e2d\u6709\u9519\u8bef\u6216\u4e0d\u5f53\u7684\u5730\u65b9\uff0c\u8bf7\u79fb\u6b65\u5230 \u6211\u7684NLP\u9879\u76ee \u8fdb\u884c\u7559\u8a00\u6307\u6b63\uff0c\u5c0f\u7f16\u5728\u6b64\u4e00\u5e76\u8c22\u8fc7\u3002     \u540e\u671f\u4f1a\u6301\u7eed\u66f4\u65b0\u3002\u3002\u3002\u3002\u3002\u3002",
            "title": "\u5728\u54ea\u53ef\u4ee5\u627e\u5230\u6211"
        }
    ]
}